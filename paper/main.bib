@article{DBLP:journals/corr/abs-1808-09701,
  author    = {Artem Yushkovskiy and
               Stavros Tripakis},
  title     = {Comparison of Two Theorem Provers: Isabelle/HOL and Coq},
  journal   = {CoRR},
  volume    = {abs/1808.09701},
  year      = {2018},
  url       = {http://arxiv.org/abs/1808.09701},
  archivePrefix = {arXiv},
  eprint    = {1808.09701},
  timestamp = {Mon, 03 Sep 2018 13:36:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1808-09701.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/corr/abs-1907-10674,
  author    = {Danil Annenkov and
               Bas Spitters},
  title     = {Towards a Smart Contract Verification Framework in Coq},
  journal   = {CoRR},
  volume    = {abs/1907.10674},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.10674},
  archivePrefix = {arXiv},
  eprint    = {1907.10674},
  timestamp = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-10674.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DBLP:conf/lpar/BlaauwbroekUG20,
  author    = {Lasse Blaauwbroek and
               Josef Urban and
               Herman Geuvers},
  editor    = {Elvira Albert and
               Laura Kov{\'{a}}cs},
  title     = {Tactic Learning and Proving for the Coq Proof Assistant},
  booktitle = {{LPAR} 2020: 23rd International Conference on Logic for Programming,
               Artificial Intelligence and Reasoning, Alicante, Spain, May 22-27,
               2020},
  series    = {EPiC Series in Computing},
  volume    = {73},
  pages     = {138--150},
  publisher = {EasyChair},
  year      = {2020},
  url       = {https://easychair.org/publications/paper/JLdB},
  timestamp = {Fri, 29 May 2020 12:05:09 +0200},
  biburl    = {https://dblp.org/rec/conf/lpar/BlaauwbroekUG20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{peltier:hal-01562944,
  TITLE = {{The Binomial Pricing Model in Finance: A Formalization in Isabelle}},
  AUTHOR = {Peltier, Nicolas and Echenim, Mnacho},
  URL = {https://hal.archives-ouvertes.fr/hal-01562944},
  BOOKTITLE = {{CADE 26}},
  ADDRESS = {Gothenburg, Sweden},
  EDITOR = {Leonardo de Moura},
  PUBLISHER = {{Springer}},
  SERIES = {26th International Conference on Automated Deduction},
  VOLUME = {10395},
  PAGES = {546-562},
  YEAR = {2017},
  HAL_ID = {hal-01562944},
  HAL_VERSION = {v1},
}
@article{DBLP:journals/pacmpl/Ahman18,
  author    = {Danel Ahman},
  title     = {Handling fibred algebraic effects},
  journal   = {Proc. {ACM} Program. Lang.},
  volume    = {2},
  number    = {{POPL}},
  pages     = {7:1--7:29},
  year      = {2018},
  url       = {https://doi.org/10.1145/3158095},
  doi       = {10.1145/3158095},
  timestamp = {Thu, 16 Apr 2020 13:51:44 +0200},
  biburl    = {https://dblp.org/rec/journals/pacmpl/Ahman18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/corr/abs-2003-02110,
  author    = {Danel Ahman and
               Matija Pretnar},
  title     = {Asynchronous effects},
  journal   = {CoRR},
  volume    = {abs/2003.02110},
  year      = {2020},
  url       = {https://arxiv.org/abs/2003.02110},
  archivePrefix = {arXiv},
  eprint    = {2003.02110},
  timestamp = {Tue, 10 Mar 2020 13:33:48 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2003-02110.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/corr/abs-cs-0603118,
  author    = {Yves Bertot},
  title     = {Coq in a Hurry},
  journal   = {CoRR},
  volume    = {abs/cs/0603118},
  year      = {2006},
  url       = {http://arxiv.org/abs/cs/0603118},
  archivePrefix = {arXiv},
  eprint    = {cs/0603118},
  timestamp = {Mon, 13 Aug 2018 16:48:09 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-cs-0603118.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DBLP:conf/itp/RoeS16,
  author    = {Kenneth Roe and
               Scott F. Smith},
  editor    = {Jasmin Christian Blanchette and
               Stephan Merz},
  title     = {CoqPIE: An {IDE} Aimed at Improving Proof Development Productivity
               - (Rough Diamond)},
  booktitle = {Interactive Theorem Proving - 7th International Conference, {ITP}
               2016, Nancy, France, August 22-25, 2016, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {9807},
  pages     = {491--499},
  publisher = {Springer},
  year      = {2016},
  url       = {https://doi.org/10.1007/978-3-319-43144-4\_32},
  doi       = {10.1007/978-3-319-43144-4\_32},
  timestamp = {Tue, 14 May 2019 10:00:37 +0200},
  biburl    = {https://dblp.org/rec/conf/itp/RoeS16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/sttt/FaithfullBTT18,
  author    = {Alexander John Faithfull and
               Jesper Bengtson and
               Enrico Tassi and
               Carst Tankink},
  title     = {Coqoon - An {IDE} for interactive proof development in Coq},
  journal   = {Int. J. Softw. Tools Technol. Transf.},
  volume    = {20},
  number    = {2},
  pages     = {125--137},
  year      = {2018},
  url       = {https://doi.org/10.1007/s10009-017-0457-2},
  doi       = {10.1007/s10009-017-0457-2},
  timestamp = {Thu, 02 Apr 2020 08:37:19 +0200},
  biburl    = {https://dblp.org/rec/journals/sttt/FaithfullBTT18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DBLP:conf/tldi/Norell09,
  author    = {Ulf Norell},
  editor    = {Andrew Kennedy and
               Amal Ahmed},
  title     = {Dependently typed programming in Agda},
  booktitle = {Proceedings of TLDI'09: 2009 {ACM} {SIGPLAN} International Workshop
               on Types in Languages Design and Implementation, Savannah, GA, USA,
               January 24, 2009},
  pages     = {1--2},
  publisher = {{ACM}},
  year      = {2009},
  url       = {https://doi.org/10.1145/1481861.1481862},
  doi       = {10.1145/1481861.1481862},
  timestamp = {Wed, 14 Nov 2018 10:58:50 +0100},
  biburl    = {https://dblp.org/rec/conf/tldi/Norell09.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/jfp/BrachthauserSO20,
  author    = {Jonathan Immanuel Brachth{\"{a}}user and
               Philipp Schuster and
               Klaus Ostermann},
  title     = {Effekt: Capability-passing style for type- and effect-safe, extensible
               effect handlers in Scala},
  journal   = {J. Funct. Program.},
  volume    = {30},
  pages     = {e8},
  year      = {2020},
  url       = {https://doi.org/10.1017/S0956796820000027},
  doi       = {10.1017/S0956796820000027},
  timestamp = {Tue, 16 Jun 2020 17:16:55 +0200},
  biburl    = {https://dblp.org/rec/journals/jfp/BrachthauserSO20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/jfp/ConventLMM20,
  author    = {Lukas Convent and
               Sam Lindley and
               Conor McBride and
               Craig McLaughlin},
  title     = {Doo bee doo bee doo},
  journal   = {J. Funct. Program.},
  volume    = {30},
  pages     = {e9},
  year      = {2020},
  url       = {https://doi.org/10.1017/S0956796820000039},
  doi       = {10.1017/S0956796820000039},
  timestamp = {Sat, 05 Sep 2020 17:51:31 +0200},
  biburl    = {https://dblp.org/rec/journals/jfp/ConventLMM20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/corr/abs-1802-06217,
  author    = {Andrej Bauer and
               Ga{\"{e}}tan Gilbert and
               Philipp G. Haselwarter and
               Matija Pretnar and
               Christopher A. Stone},
  title     = {Design and Implementation of the Andromeda Proof Assistant},
  journal   = {CoRR},
  volume    = {abs/1802.06217},
  year      = {2018},
  url       = {http://arxiv.org/abs/1802.06217},
  archivePrefix = {arXiv},
  eprint    = {1802.06217},
  timestamp = {Mon, 13 Aug 2018 16:47:28 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1802-06217.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DBLP:conf/icms/BauerHP20,
  author    = {Andrej Bauer and
               Philipp G. Haselwarter and
               Anja Petkovic},
  editor    = {Anna Maria Bigatti and
               Jacques Carette and
               James H. Davenport and
               Michael Joswig and
               Timo de Wolff},
  title     = {Equality Checking for General Type Theories in Andromeda 2},
  booktitle = {Mathematical Software - {ICMS} 2020 - 7th International Conference,
               Braunschweig, Germany, July 13-16, 2020, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {12097},
  pages     = {253--259},
  publisher = {Springer},
  year      = {2020},
  url       = {https://doi.org/10.1007/978-3-030-52200-1\_25},
  doi       = {10.1007/978-3-030-52200-1\_25},
  timestamp = {Wed, 08 Jul 2020 15:43:35 +0200},
  biburl    = {https://dblp.org/rec/conf/icms/BauerHP20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DBLP:conf/esop/AhmanB20,
  author    = {Danel Ahman and
               Andrej Bauer},
  editor    = {Peter M{\"{u}}ller},
  title     = {Runners in Action},
  booktitle = {Programming Languages and Systems - 29th European Symposium on Programming,
               {ESOP} 2020, Held as Part of the European Joint Conferences on Theory
               and Practice of Software, {ETAPS} 2020, Dublin, Ireland, April 25-30,
               2020, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {12075},
  pages     = {29--55},
  publisher = {Springer},
  year      = {2020},
  url       = {https://doi.org/10.1007/978-3-030-44914-8\_2},
  doi       = {10.1007/978-3-030-44914-8\_2},
  timestamp = {Mon, 20 Apr 2020 16:36:31 +0200},
  biburl    = {https://dblp.org/rec/conf/esop/AhmanB20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{Z32008,
   abstract = {Satisfiability Modulo Theories (SMT) problem is a decision problem for logical first order formulas with respect to combinations of background theories such as: arithmetic, bit-vectors, arrays, and uninterpreted functions. Z3 is a new and efficient SMT Solver freely available from Microsoft Research. It is used in various software verification and analysis applications. © 2008 Springer-Verlag Berlin Heidelberg.},
   author = {Leonardo De Moura and Nikolaj Bjørner},
   doi = {10.1007/978-3-540-78800-3_24},
   isbn = {3540787992},
   issn = {03029743},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   pages = {337-340},
   publisher = {Springer, Berlin, Heidelberg},
   title = {Z3: An efficient SMT Solver},
   volume = {4963 LNCS},
   url = {http://research.microsoft.com/projects/z3.},
   year = {2008},
}
@article{Ziliani2013,
author    = {Beta Ziliani and
               Derek Dreyer and
               Neelakantan R. Krishnaswami and
               Aleksandar Nanevski and
               Viktor Vafeiadis},
  title     = {Mtac: {A} monad for typed tactic programming in Coq},
  journal   = {J. Funct. Program.},
  volume    = {25},
  year      = {2015},
  url       = {https://doi.org/10.1017/S0956796815000118},
  doi       = {10.1017/S0956796815000118},
  timestamp = {Thu, 15 Jun 2017 21:30:55 +0200},
  biburl    = {https://dblp.org/rec/journals/jfp/ZilianiDKNV15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Bauer2018,
   author = {Andrej Bauer and Gaëtan Gilbert and Philipp G Haselwarter and Matija Pretnar and Christopher A Stone},
   journal = {CoRR},
   title = {Design and Implementation of the Andromeda Proof Assistant},
   volume = {abs/1802.06217},
   url = {http://arxiv.org/abs/1802.06217},
   year = {2018},
}
@inproceedings{Bauer2020,
   author = {Andrej Bauer and Philipp G Haselwarter and Anja Petkovic},
   doi = {10.1007/978-3-030-52200-1_25},
   editor = {Anna Maria Bigatti and Jacques Carette and James H Davenport and Michael Joswig and Timo de Wolff},
   journal = {Mathematical Software - ICMS 2020 - 7th International Conference,
Braunschweig, Germany, July 13-16, 2020, Proceedings},
   pages = {253-259},
   publisher = {Springer},
   title = {Equality Checking for General Type Theories in Andromeda 2},
   volume = {12097},
   url = {https://doi.org/10.1007/978-3-030-52200-1_25},
   year = {2020},
}
@inproceedings{MetaFstar,
   abstract = {We introduce Meta-F*, a tactics and metaprogramming framework for the F* program verifier. The main novelty of Meta-F* is allowing the use of tactics and metaprogramming to discharge assertions not solvable by SMT, or to just simplify them into well-behaved SMT fragments. Plus, Meta-F* can be used to generate verified code automatically. Meta-F* is implemented as an F* effect, which, given the powerful effect system of F*, heavily increases code reuse and even enables the lightweight verification of metaprograms. Metaprograms can be either interpreted, or compiled to efficient native code that can be dynamically loaded into the F* type-checker and can interoperate with interpreted code. Evaluation on realistic case studies shows that Meta-F* provides substantial gains in proof development, efficiency, and robustness.},
   author = {Guido Martínez and Danel Ahman and Victor Dumitrescu and Nick Giannarakis and Chris Hawblitzel and Cătălin Hriţcu and Monal Narasimhamurthy and Zoe Paraskevopoulou and Clément Pit-Claudel and Jonathan Protzenko and Tahina Ramananandro and Aseem Rastogi and Nikhil Swamy},
   doi = {10.1007/978-3-030-17184-1_2},
   isbn = {9783030171834},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Metaprogramming,Program verification,Proof assistants,SMT solvers,Tactics,Verification conditions},
   month = {4},
   pages = {30-59},
   publisher = {Springer Verlag},
   title = {Meta-F*: Proof Automation with SMT, Tactics, and Metaprograms},
   volume = {11423 LNCS},
   url = {https://doi.org/10.1007/978-3-030-17184-1_2},
   year = {2019},
}
@article{Miranda-Perea2020,
   abstract = {Equational reasoning arises in many areas of mathematics and computer science. It is a cornerstone of algebraic reasoning and results essential in tasks of specification and verification in functional programming, where a program is mainly a set of equations. The usual manipulation of identities while conducting informal proofs obviates many intermediate steps that are neccesary while developing them using a formal system, such as the equationally complete Birkhoff calculus $\{\mathcal\{B\}\}$. This deductive system does not fit in the common manner of doing mathematical proofs, and it is not compatible with the mechanisms of proof assistants. The aim of this work is to provide a deductive system $\{\mathcal\{B\}\}^\{\textrm\{GOAL\}\}$ for equality, equivalent to $\{\mathcal\{B\}\}$ but suitable for constructing equational proofs in a backward fashion. This feature makes it adequate for interactive proof-search in the approach of proof assistants. This will be achieved by turning $\{\mathcal\{B\}\}^\{\textrm\{GOAL\}\}$ into a transition system of formal tactics in the style of Edinburgh LCF, such transformation allows us to give a direct formal definition of backward proof in equational logic.},
   author = {Favio E Miranda-Perea and Lourdes del Carmen González Huesca and P Selene Linares-Arévalo},
   doi = {10.1093/jigpal/jzaa013},
   issn = {1367-0751},
   journal = {Logic Journal of the IGPL},
   month = {5},
   publisher = {Oxford University Press (OUP)},
   title = {Interactive proof-search for equational reasoning},
   url = {https://academic.oup.com/jigpal/advance-article/doi/10.1093/jigpal/jzaa013/5842268},
   year = {2020},
}
@article{Wiedijk2003,
   abstract = {We compare fifteen systems for the formalizations of mathematics with the computer. We present several tables that list various properties of these programs. The three main dimensions on which we compare these systems are: the size of their library, the strength of their logic and their level of automation. © Springer-Verlag Berlin Heidelberg 2003.},
   author = {Freek Wiedijk},
   doi = {10.1007/3-540-36469-2_15},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   pages = {188-202},
   publisher = {Springer Verlag},
   title = {Comparing mathematical provers},
   volume = {2594},
   url = {https://link.springer.com/chapter/10.1007/3-540-36469-2_15},
   year = {2003},
}
@article{Anapa2010,
   abstract = {The aim of this study is to determine the students' perceptions of mathematical proving who were attending the department of Mathematics and Computer Sciences in Arts and Science Faculty and the Department of Elementary School Mathematics Teaching in Education Faculty. For this purpose, the scale developed by Almedia (2001) and adapted to Turkish by Morali, Uǧurel, Türnüklü and Yeşildere (2006) was administered to the students in related departments. The findings of this study were statistically examined in terms of the students' departments and of their certain characteristics. © 2010 Elsevier Ltd. All rights reserved.},
   author = {Pınar Anapa and Hatice Şamkar},
   doi = {10.1016/j.sbspro.2010.03.399},
   issn = {18770428},
   issue = {2},
   journal = {Procedia - Social and Behavioral Sciences},
   keywords = {ANOVA,Factor analysis,Mathematical Proof,Students' Perception of mathematical proof,independent t test},
   pages = {2700-2706},
   title = {Investigation of undergraduate students’ perceptions of mathematical proof},
   volume = {2},
   url = {https://linkinghub.elsevier.com/retrieve/pii/S1877042810004398},
   year = {2010},
}
@inproceedings{Knobelsdorf2017,
   abstract = {This paper presents first results of an evaluation study investigating whether an interactive theorem prover l\ike Coq can be used to help undergraduate computer science (CS) students learn mathematical proving within the field of theory of computation. Set within an educational design research approach and building on cognitive apprenticeship and socio cultures cognition theories, we have collected empirical, mainly qualitative observational data focusing on students' activities with Coq in an introductory course specifically created for that matter. Our results strengthen the assumption that a theorem prover like Coq, indeed, can be beneficial in mediating undergraduate students' activities in learning formal proving. In comparison to pen & paper proofs, students were profiting strongly from the system's immediate feedback and scaffolding. These results encourage the idea to extend the scientifically dominated use of theorem provers like Coq to pedagogical use cases in undergraduate CS education.},
   author = {Maria Knobelsdorf and Christiane Frede and Sebastian Böhne and Christoph Kreitz},
   city = {New York, NY, USA},
   doi = {10.1145/3105726.3106184},
   isbn = {9781450349680},
   journal = {ICER 2017 - Proceedings of the 2017 ACM Conference on International Computing Education Research},
   keywords = {Computer science education,Data structures,Distributed cognition theory,Logic,Observational study,Proofs,Qualitative research,Students,Theorem prover,Theory of computation},
   month = {8},
   pages = {83-92},
   publisher = {Association for Computing Machinery, Inc},
   title = {Theorem provers as a learning tool in theory of computation},
   url = {https://dl.acm.org/doi/10.1145/3105726.3106184},
   year = {2017},
}
@inproceedings{Knobelsdorf2016,
   abstract = {This paper describes a qualitative study investigating how undergraduate CS majors solved assignments from a Theory of Computation (ToC) course in individually-formed study groups. We use Distributed Cognition Theory as the underlying theoretical framework and ask two research questions: 1) How do students use mathematical notations to work on their assignment, and 2) how and by which means do students assure themselves that their approach is correct? We observed 12 undergraduate CS majors tasked with developing a proof for NP-completeness working in three study groups. Data collected in this study points to students' lack of working proficiency, especially with regard to creating mathematical inscriptions, as a key aspect in their difficulties in solving ToC assignments. This result is significant because it highlights the need to reexamine widely used assumptions about reasons for students' difficulties with ToC, e.g., lack of interest due to abstract and theoretical nature of ToC.},
   author = {Maria Knobelsdorf and Christiane Frede},
   city = {New York, NY, USA},
   doi = {10.1145/2960310.2960331},
   isbn = {9781450344494},
   journal = {ICER 2016 - Proceedings of the 2016 ACM Conference on International Computing Education Research},
   keywords = {CS Ed,Distributed cognition theory,NP-completeness proofs, ethnographical approach,Observational study,Qualitative research,Students,Theory of computation},
   month = {8},
   pages = {73-82},
   publisher = {Association for Computing Machinery, Inc},
   title = {Analyzing student practices in theory of computation in light of distributed cognition theory},
   url = {https://dl.acm.org/doi/10.1145/2960310.2960331},
   year = {2016},
}
@article{Ariola1997,
   abstract = {Plotkin (1975) showed that the lambda calculus is a good model of the evaluation process for call-by-name functional programs. Reducing programs to constants or lambda abstractions according to the leftmost-outermost strategy exactly mirrors execution on an abstract machine like Landin's SECD machine. The machine-based evaluator returns a constant or the token closure if and only if the standard reduction sequence starting at the same program will end in the same constant or in some lambda abstraction. However, the calculus does not capture the sharing of the evaluation of arguments that lazy implementations use to speed up the execution. More precisely, a lazy implementation evaluates procedure arguments only when needed and then only once. All other references to the formal procedure parameter re-use the value of the first argument evaluation. The mismatch between the operational semantics of the lambda calculus and the actual behavior of the prototypical implementation is a major obstacle for compiler writers. Unlike implementors of the leftmost-outermost strategy or of a call-by-value language, implementors of lazy systems cannot easily explain the behavior of their evaluator in terms of source level syntax. Hence, they often cannot explain why a certain syntactic transformation 'works' and why another doesn't. In this paper we develop an equational characterization of the most popular lazy implementation technique - traditionally called 'call-by-need' - and prove it correct with respect to the original lambda calculus. The theory is a strictly smaller theory than Plotkin's call-by-name lambda calculus. Immediate applications of the theory concern the correctness proofs of a number of implementation strategies, e.g. the call-by-need continuation passing transformation and the realization of sharing via assignments. Some of this material first appeared in a paper presented at the 1995 ACM Conference on the Principles of Programming Languages. The paper was a joint effort with Maraist, Odersky and Wadler, who had independently developed a different equational characterization of call-by-need. We contrast our work with that of Maraist et al. in the body of this paper where appropriate.},
   author = {Zena M. Ariola and Matthias Felleisen},
   doi = {10.1017/S0956796897002724},
   issn = {09567968},
   journal = {Journal of Functional Programming},
   title = {The call-by-need lambda calculus},
   year = {1997},
}
@article{Garcia2010,
   abstract = {The call-by-need lambda calculus provides an equational framework for reasoning syntactically about lazy evaluation. This paper examines its operational characteristics. By a series of reasoning steps, we systematically unpack the standard-order reduction relation of the calculus and discover a novel abstract machine definition which, like the calculus, goes "under lambdas." We prove that machine evaluation is equivalent to standard-order evaluation. Unlike traditional abstract machines, delimited control plays a significant role in the machine's behavior. In particular, the machine replaces the manipulation of a heap using store-based effects with disciplined management of the evaluation stack using control-based effects. In short, state is replaced with control. To further articulate this observation, we present a simulation of call-by-need in a call-by-value language using delimited control operations. © R. Garcia, A. Lumsdaine, and A. Sabry.},
   author = {Ronald Garcia and Andrew Lumsdaine and Amr Sabry},
   doi = {10.2168/LMCS-6(3:1)2010},
   issn = {18605974},
   journal = {Logical Methods in Computer Science},
   keywords = {Abstract machines,Call-by-need,Delimited continuations,Lambda calculus,Reduction semantics},
   title = {Lazy evaluation and delimited control},
   year = {2010},
}
@inproceedings{McDermott2019,
   abstract = {Traditionally, reasoning about programs under varying evaluation regimes (call-by-value, call-by-name etc.) was done at the meta-level, treating them as term rewriting systems. Levy’s call-by-push-value (CBPV) calculus provides a more powerful approach for reasoning, by treating CBPV terms as a common intermediate language which captures both call-by-value and call-by-name, and by allowing equational reasoning about changes to evaluation order between or within programs. We extend CBPV to additionally deal with call-by-need, which is non-trivial because of shared reductions. This allows the equational reasoning to also support call-by-need. As an example, we then prove that call-by-need and call-by-name are equivalent if nontermination is the only side-effect in the source language. We then show how to incorporate an effect system. This enables us to exploit static knowledge of the potential effects of a given expression to augment equational reasoning; thus a program fragment might be invariant under change of evaluation regime only because of knowledge of its effects.},
   author = {Dylan McDermott and Alan Mycroft},
   doi = {10.1007/978-3-030-17184-1_9},
   isbn = {9783030171834},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Extended Call-by-Push-Value: Reasoning About Effectful Programs and Evaluation Order},
   volume = {11423 LNCS},
   year = {2019},
}
@inproceedings{Gaboardi2016,
   abstract = {Effects and coeffects are two general, complementary aspects of program behaviour. They roughly correspond to computations which change the execution context (effects) versus computations which make demands on the context (coeffects). Effectful features include partiality, non-determinism, input-output, state, and exceptions. Coeffectful features include resource demands, variable access, notions of linearity, and data input requirements. The effectful or coeffectful behaviour of a program can be captured and described via type-based analyses, with fine grained information provided by monoidal effect annotations and semiring coeffects. Various recent work has proposed models for such typed calculi in terms of graded (strong) monads for effects and graded (monoidal) comonads for coeffects. Effects and coeffects have been studied separately so far, but in practice many computations are both effectful and coeffectful, e.g., possibly throwing exceptions but with resource requirements. To remedy this, we introduce a new general calculus with a combined effect-coeffect system. This can describe both the changes and requirements that a program has on its context, as well as interactions between these effectful and coeffectful features of computation. The effect-coeffect system has a denotational model in terms of effect-graded monads and coeffect-graded comonads where interaction is expressed via the novel concept of graded distributive laws. This graded semantics unifies the syntactic type theory with the denotational model. We show that our calculus can be instantiated to describe in a natural way various different kinds of interaction between a program and its evaluation context.},
   author = {Marco Gaboardi and Shin Ya Katsumata and Dominic Orchard and Flavien Breuvart and Tarmo Uustalu},
   doi = {10.1145/2951913.2951939},
   isbn = {9781450342193},
   journal = {ICFP 2016 - Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming},
   title = {Combining effects and coeffects via grading},
   year = {2016},
}
@inproceedings{Atkey2018,
   abstract = {We present Quantitative Type Theory, a Type Theory that records usage information for each variable in a judgement, based on a previous system by McBride. The usage information is used to give a realizability semantics using a variant of Linear Combinatory Algebras, refining the usual realizability semantics of Type Theory by accurately tracking resource behaviour. We define the semantics in terms of Quantitative Categories with Families, a novel extension of Categories with Families for modelling resource sensitive type theories.},
   author = {Robert Atkey},
   doi = {10.1145/3209108.3209189},
   isbn = {9781450355834},
   issn = {10436871},
   journal = {Proceedings - Symposium on Logic in Computer Science},
   title = {Syntax and semantics of quantitative type theory},
   year = {2018},
}
@article{Awodey2018,
   abstract = {The notion of a natural model of type theory is defined in terms of that of a representable natural transfomation of presheaves. It is shown that such models agree exactly with the concept of a category with families in the sense of Dybjer, which can be regarded as an algebraic formulation of type theory. We determine conditions for such models to satisfy the inference rules for dependent sums Σ, dependent products Π and intensional identity types Id, as used in homotopy type theory. It is then shown that a category admits such a model if it has a class of maps that behave like the abstract fibrations in axiomatic homotopy theory: They should be stable under pullback, closed under composition and relative products, and there should be weakly orthogonal factorizations into the class. It follows that many familiar settings for homotopy theory also admit natural models of the basic system of homotopy type theory.},
   author = {Steve Awodey},
   doi = {10.1017/S0960129516000268},
   issn = {09601295},
   issue = {2},
   journal = {Mathematical Structures in Computer Science},
   title = {Natural models of homotopy type theory},
   volume = {28},
   year = {2018},
}
@inproceedings{Cohen2018,
   abstract = {This paper presents a type theory in which it is possible to directly manipulate $n$-dimensional cubes (points, lines, squares, cubes, etc.) based on an interpretation of dependent type theory in a cubical set model. This enables new ways to reason about identity types, for instance, function extensionality is directly provable in the system. Further, Voevodsky's univalence axiom is provable in this system. We also explain an extension with some higher inductive types like the circle and propositional truncation. Finally we provide semantics for this cubical type theory in a constructive meta-theory.},
   author = {Cyril Cohen and Thierry Coquand and Simon Huber and Anders Mörtberg},
   doi = {10.4230/LIPIcs.TYPES.2015.5},
   isbn = {9783959770309},
   issn = {18688969},
   journal = {Leibniz International Proceedings in Informatics, LIPIcs},
   keywords = {Cubical sets,Dependent type theory,Univalence axiom},
   month = {3},
   pages = {51-534},
   publisher = {Schloss Dagstuhl- Leibniz-Zentrum fur Informatik GmbH, Dagstuhl Publishing},
   title = {Cubical type theory: A constructive interpretation of the univalence axiom},
   volume = {69},
   year = {2018},
}
@article{,
   abstract = {The standard reading of type theory through the lens of category theory is based on the idea of viewing a type system as a category of well-typed terms. We propose a basic revision of this reading: rather than interpreting type systems as categories, we describe them as functors from a category of typing derivations to a category of underlying terms. Then, turning this around, we explain how in fact any functor gives rise to a generalized type system, with an abstract notion of typing judgment, typing derivations and typing rules. This leads to a purely categorical reformulation of various natural classes of type systems as natural classes of functors. The main purpose of this paper is to describe the general framework (which can also be seen as providing a categorical analysis of refinement types), and to present a few applications. As a larger case study, we revisit Reynolds’ paper on “The Meaning of Types” (2000), showing how the paper’s main results may be reconstructed along these lines.},
   author = {Paul-André Melliès and Noam Zeilberger},
   doi = {10.1145/2775051.2676970},
   issn = {03621340},
   issue = {1},
   journal = {ACM SIGPLAN Notices},
   title = {Functors are Type Refinement Systems},
   volume = {50},
   year = {2015},
}
@article{,
   abstract = {We develop the operational semantics of an untyped probabilistic lambda-calculus with continuous distributions, as a foundation for universal probabilistic programming languages such as Church, Anglican, and Venture. Our first contribution is to adapt the classic operational semantics of lambda-calculus to a continuous setting via creating a measure space on terms and defining step-indexed approximations. We prove equivalence of big-step and small-step formulations of this distribution-based semantics. To move closer to inference techniques, we also define the sampling-based semantics of a term as a function from a trace of random samples to a value. We show that the distribution induced by integrating over all traces equals the distribution-based semantics. Our second contribution is to formalize the implementation technique of trace Markov chain Monte Carlo (MCMC) for our calculus and to show its correctness. A key step is defining sufficient conditions for the distribution induced by trace MCMC to converge to the distribution-based semantics. To the best of our knowledge, this is the first rigorous correctness proof for trace MCMC for a higher-order functional language.},
   author = {Johannes Borgström and Ugo Dal Lago and Andrew D. Gordon and Marcin Szymczak},
   doi = {10.1145/3022670.2951942},
   issn = {03621340},
   issue = {9},
   journal = {ACM SIGPLAN Notices},
   title = {A lambda-calculus foundation for universal probabilistic programming},
   volume = {51},
   year = {2016},
}
@inproceedings{,
   abstract = {Bidirectional transformations (bx) support principled consistency maintenance between data sources. Each data source corresponds to one perspective on a composite system, manifested by operations to 'get' and 'set' a view of the whole from that particular perspective. Bx are important in a wide range of settings, including databases, interactive applications, and model-driven development. We show that bx are naturally modelled in terms of mutable state; in particular, the 'set' operations are stateful functions. This leads naturally to considering bx that exploit other computational effects too, such as I/O, nondeterminism, and failure, all largely ignored in the bx literature to date. We present a semantic foundation for symmetric bidirectional transformations with effects. We build on the mature theory of monadic encapsulation of effects in functional programming, develop the equational theory and important combinators for effectful bx, and provide a prototype implementation in Haskell along with several illustrative examples.},
   author = {Faris Abou-Saleh and James Cheney and Jeremy Gibbons and James McKinna and Perdita Stevens},
   doi = {10.1007/978-3-319-19797-5_9},
   isbn = {9783319197968},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Notions of bidirectional computation and entangled state monads},
   volume = {9129},
   year = {2015},
}
@inproceedings{,
   abstract = {Bidirectional transformations (bx) have primarily been modeled as pure functions, and do not account for the possibility of the side-effects that are available in most programming languages. Recently several formulations of bx that use monads to account for effects have been proposed, both among practitioners and in academic research. The combination of bx with effects turns out to be surprisingly subtle, leading to problems with some of these proposals and increasing the complexity of others. This paper reviews the proposals for monadic lenses to date, and offers some improved definitions, paying particular attention to the obstacles to naively adding monadic effects to existing definitions of pure bx such as lenses and symmetric lenses, and the subtleties of equivalence of symmetric bidirectional transformations in the presence of effects.},
   author = {Faris Abou-Sale and James Cheney and Jeremy Gibbons and James McKinna and Perdita Stevens},
   doi = {10.1007/978-3-319-30936-1_1},
   isbn = {9783319309354},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Reflections on monadic lenses},
   volume = {9600},
   year = {2016},
}
@inproceedings{Mokhov2017,
   abstract = {The paper presents a minimalistic and elegant approach to working with graphs in Haskell. It is built on a rigorous mathematical foun-dation — an algebra of graphs — that allows us to apply equational reasoning for proving the correctness of graph transformation al-gorithms. Algebraic graphs let us avoid partial functions typically caused by 'malformed graphs' that contain an edge referring to a non-existent vertex. This helps to liberate APIs of existing graph libraries from partial functions. The algebra of graphs can represent directed, undirected, reflex-ive and transitive graphs, as well as hypergraphs, by appropriately choosing the set of underlying axioms. The flexibility of the ap-proach is demonstrated by developing a library for constructing and transforming polymorphic graphs.},
   author = {Andrey Mokhov},
   doi = {10.1145/3122955.3122956},
   isbn = {9781450351829},
   issn = {0362-1340},
   journal = {Proceedings of the 10th ACM SIGPLAN International Symposium on Haskell  - Haskell 2017},
   title = {Algebraic graphs with class (functional pearl)},
   year = {2017},
}
@article{Pottier2014,
   abstract = {Type inference - the problem of determining whether a program is well-typed - is well-understood. In contrast, elaboration - the task of constructing an explicitly-typed representation of the program - seems to have received relatively little attention, even though, in a non-local type inference system, it is non-trivial. We show that the constraint-based presentation of Hindley-Milner type inference can be extended to deal with elaboration, while preserving its elegance. This involves introducing a new notion of "constraint with a value", which forms an applicative functor.},
   author = {François Pottier},
   doi = {10.1145/2628136.2628145},
   isbn = {9781450328739},
   issn = {15232867},
   journal = {Proceedings of the 19th ACM SIGPLAN international conference on Functional programming - ICFP '14},
   title = {Hindley-milner elaboration in applicative style},
   year = {2014},
}
@article{Ramsey2014,
   abstract = {This paper presents a personal, qualitative case study of a first course using How to Design Programs and its functional teaching languages. The paper reconceptualizes the book's six-step design process as an eight-step design process ending in a new "review and refactor" step. It recommends specific approaches to students' difficulties with function descriptions, function templates, data examples, and other parts of the design process. It connects the process to interactive "world programs." It recounts significant, informative missteps in course design and delivery. Finally, it identifies some unsolved teaching problems and some potential solutions.},
   author = {Norman Ramsey},
   doi = {10.1145/2628136.2628137},
   isbn = {9781450328739},
   issn = {15232867},
   issue = {9},
   journal = {SIGPLAN Not.},
   title = {On Teaching *How to Design Programs*: Observations from a Newcomer},
   volume = {49},
   year = {2014},
}
@article{Vazou2014,
   abstract = {Haskell has many delightful features. Perhaps the one most beloved by its users is its type system that allows developers to specify and verify a variety of program properties at compile time. However, many properties, typically those that depend on relationships be-tween program values are impossible, or at the very least, cumber-some to encode within the existing type system. Many such prop-erties can be verified using a combination of Refinement Types and external SMT solvers. We describe the refinement type checker LIQUIDHASKELL, which we have used to specify and verify a variety of properties of over 10,000 lines of Haskell code from various popular libraries, including containers, hscolour, bytestring, text, vector-algorithms and xmonad. First, we present a high-level overview of LIQUIDHASKELL, through a tour of its features. Second, we present a qualitative discussion of the kinds of properties that can be checked – ranging from generic application independent criteria like totality and ter-mination, to application specific concerns like memory safety and data structure correctness invariants. Finally, we present a quanti-tative evaluation of the approach, with a view towards measuring the efficiency and programmer effort required for verification, and discuss the limitations of the approach.},
   author = {Niki Vazou and Eric L. Seidel and Ranjit Jhala},
   doi = {10.1145/2633357.2633366},
   isbn = {9781450330411},
   issn = {03621340},
   issue = {2},
   journal = {Proceedings of the 2014 ACM SIGPLAN symposium on Haskell - Haskell '14},
   title = {LiquidHaskell: Experience with Refinement Types in the Real World},
   year = {2014},
}
@article{Ko2017,
   abstract = {<p>Dependently typed programming advocates the use of various indexed versions of the same shape of data, but the formal relationship amongst these structurally similar datatypes usually needs to be established manually and tediously. Ornaments have been proposed as a formal mechanism to manage the relationships between such datatype variants. In this paper, we conduct a case study under an ornament framework; the case study concerns programming binomial heaps and their operations — including insertion and minimum extraction — by viewing them as lifted versions of binary numbers and numeric operations. We show how current dependently typed programming technology can lead to a clean treatment of the binomial heap constraints when implementing heap operations. We also identify some gaps between the current technology and an ideal dependently typed programming language that we would wish to have for our development.</p>},
   author = {Hsiang Shang Ko and Jeremy Gibbons},
   doi = {10.1017/S0956796816000307},
   issn = {14697653},
   journal = {Journal of Functional Programming},
   title = {Programming with ornaments},
   volume = {27},
   year = {2017},
}
@inproceedings{Maurer2017,
   abstract = {Many fields of study in compilers give rise to the concept of a join point—a place where different execution paths come together. Join points are often treated as functions or continuations, but we believe it is time to study them in their own right. We show that adding join points to a direct-style functional intermediate language is a simple but powerful change that allows new optimizations to be performed, including a significant improvement to list fusion. Finally, we report on recent work on adding join points to the intermediate language of the Glasgow Haskell Compiler.},
   author = {Luke Maurer and Paul Downen and Zena M. Ariola and Simon Peyton Jones},
   doi = {10.1145/3062341.3062380},
   isbn = {9781450349888},
   issn = {03621340},
   journal = {Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation  - PLDI 2017},
   title = {Compiling without continuations},
   year = {2017},
}
@inproceedings{Gibbons2017,
   abstract = {Much of the expressive power of array-oriented languages such as Iverson’s APL and J comes from their implicit lifting of scalar operations to act on higher-ranked data, for example to add a value to each element of a vector, or to add two compatible matrices pointwise. It is considered a shape error to attempt to combine arguments of incompatible shape, such as a 3-vector with a 4-vector. APL and J are dynamically typed, so such shape errors are caught only at run-time. Recent work by Slepak et al. develops a custom type system for an array-oriented language, statically ruling out such errors. We show here that such a custom language design is unnecessary: the requisite compatibility checks can already be captured in modern expressive type systems, as found for example in Haskell; moreover, generative type-driven programming can exploit that static type information constructively to automatically induce the appropriate liftings. We show also that the structure of multi-dimensional data is inherently a matter of Naperian applicative functors—lax monoidal functors, with strength, commutative up to isomorphism under composition—that also support traversal.},
   author = {Jeremy Gibbons},
   doi = {10.1007/978-3-662-54434-1_21},
   isbn = {9783662544334},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {APLicative programming with Naperian functors},
   volume = {10201 LNCS},
   year = {2017},
}
@article{Kammar2017,
   abstract = {We present a straightforward, sound Hindley-Milner polymorphic type system for algebraic effects and handlers in a call-by-value calculus, which allows type variable generalisation of arbitrary com-putations, not just values. This result is surprising. On the one hand, the soundness of unrestricted call-by-value Hindley-Milner polymorphism is known to fail in the presence of computational effects such as reference cells and continuations. On the other hand, many programming examples can be recast to use effect handlers instead of these effects. Analysing the expressive power of effect handlers with respect to state effects, we claim handlers cannot express reference cells, and show they can simulate dynamically scoped state.},
   author = {Ohad Kammar and Matija Pretnar},
   doi = {10.1017/S0956796816000320},
   issn = {14697653},
   journal = {Journal of Functional Programming},
   title = {No value restriction is needed for algebraic effects and handlers},
   year = {2017},
}
@inproceedings{Jeffrey2014,
   abstract = {Abstract—Functional Reactive Programming (FRP) is an ap- proach to streaming data with a pure functional semantics as time-indexed values. In previous work, we showed that Linear- time Temporal Logic (LTL) can be used as a type system for discrete-time FRP, and that functional reactive primitives perform two roles: as combinators for building streams of data, and as proof rules for constructive LTL. In this paper, we add a third role, by showing that FRP combinators can be used to define streams of types, and that these functional reactive types can be viewed both as a constructive temporal logic, and as the types for functional reactive programs. As an application of functional reactive types, we show that past-time LTL (pLTL) can be extended with FRP to get a logic pLTL+FRP. This logic is expressed as streams of boolean expressions, and so bounded satisfiability of pLTL can be translated to Satisfiability Modulo Theory (SMT). Thus, pLTL+FRP can be used as a constraint language for problems which mix properties of data with temporal properties.},
   author = {Alan Jeffrey},
   doi = {10.1145/2603088.2603106},
   isbn = {9781450328869},
   journal = {Proceedings of the Joint Meeting of the Twenty-Third EACSL Annual Conference on Computer Science Logic (CSL) and the Twenty-Ninth Annual ACM/IEEE Symposium on Logic in Computer Science (LICS) - CSL-LICS '14},
   title = {Functional reactive types},
   year = {2014},
}
@article{,
   author = {J Gonçalves},
   journal = {Proceedings of the 6th ACM SIGPLAN International Workshop on Functional Art, Music, Modeling, and Design},
   title = {Abstract Nonsense},
   year = {2018},
}
@inproceedings{Archipoff2017,
   author = {Simon Archipoff and David Janin},
   city = {New York, New York, USA},
   doi = {10.1145/3122938.3122943},
   isbn = {9781450351805},
   journal = {Proceedings of the 5th ACM SIGPLAN International Workshop on Functional Art, Music, Modeling, and Design  - FARM 2017},
   keywords = {3D programming,model based programming language,temporal animation},
   pages = {36-47},
   publisher = {ACM Press},
   title = {Unified media programming: an algebraic approach},
   url = {http://dl.acm.org/citation.cfm?doid=3122938.3122943},
   year = {2017},
}
@inproceedings{Torrens2017,
   abstract = {© 2017 ACM. Compiler theory is usually studied individually according to the paradigms of the programming language being compiled. As noted by Kelsey, though the static single assignment (SSA) form has been used as intermediate language for imperative language compilers, and some variant of a continuation passing style (CPS) lambda calculus has been used as intermediate language for functional language compilers, they are (almost) equivalent and it is possible to draw syntactic translations between them. This short paper aims to present an untyped intermediate language which may be interpreted as both SSA and CPS, in order to provide a common language for both imperative and functional compilers, as well to take advantage of optimizations designed for either one of the approaches. Finally, potential variants and research opportunities are discussed.},
   author = {P. Torrens and C. Vasconcellos and J. Gonçalves},
   doi = {10.1145/3125374.3125377},
   isbn = {9781450353892},
   journal = {ACM International Conference Proceeding Series},
   keywords = {Continuation passing style,Intermediate languages,Static single assignment},
   title = {A hybrid intermediate language between SSA and CPS: Short Paper},
   volume = {Part F1308},
   year = {2017},
}
@article{,
   abstract = {Effect systems have the potential to help software developers, but their practical adoption has been very limited. We conjecture that this limited adoption is due in part to the difficulty of transitioning from a system where effects are implicit and unrestricted to a system with a static effect discipline, which must settle for conservative checking in order to be decidable. To address this hindrance, we develop a theory of gradual effect checking, which makes it possible to incrementally annotate and statically check effects, while still rejecting statically inconsistent programs. We extend the generic type-and-effect framework of Marino and Millstein with a notion of unknown effects, which turns out to be significantly more subtle than unknown types in traditional gradual typing. We appeal to abstract interpretation to develop and validate the concepts of gradual effect checking. We also demonstrate how an effect system formulated in Marino and Millstein’s framework can be automatically extended to support gradual checking.},
   author = {Felipe Bañados Schwerter and Ronald Garcia and Éric Tanter},
   doi = {10.1145/2692915.2628149},
   isbn = {9781450328739},
   issn = {03621340},
   journal = {ACM SIGPLAN Notices},
   title = {A theory of gradual effect systems},
   year = {2014},
}
@article{Gambino2013,
   abstract = {We study polynomial functors over locally cartesian closed categories. After setting up the basic theory, we show how polynomial functors assemble into a double category, in fact a framed bicategory. We show that the free monad on a polynomial endofunctor is polynomial. The relationship with operads and other related notions is explored.},
   author = {Nicola Gambino and Joachim Kock},
   doi = {10.1017/S0305004112000394},
   issn = {03050041},
   journal = {Mathematical Proceedings of the Cambridge Philosophical Society},
   title = {Polynomial functors and polynomial monads},
   year = {2013},
}
@article{Jeffrey2012,
   abstract = {Functional Reactive Programming (FRP) is a form of reactive programming whose model is pure functions over signals. FRP is often expressed in terms of arrows with loops, which is the type class for a Freyd category (that is a premonoidal category with a cartesian centre) equipped with a premonoidal trace. This type system suffices to define the dataflow structure of a reactive program, but does not express its temporal properties. In this paper, we show that Linear-time Temporal Logic (LTL) is a natural extension of the type system for FRP, which constrains the temporal behaviour of reactive programs. We show that a constructive LTL can be defined in a dependently typed functional language, and that reactive programs form proofs of constructive LTL properties. In particular, implication in LTL gives rise to stateless functions on streams, and the "constrains" modality gives rise to causal functions. We show that reactive programs form a partially traced monoidal category, and hence can be given as a form of arrows with loops, where the type system enforces that only decoupled functions can be looped.},
   author = {Alan Jeffrey},
   doi = {10.1145/2103776.2103783},
   isbn = {9781450311250},
   issn = {07308566},
   journal = {Proceedings of the sixth workshop on Programming languages meets program verification},
   keywords = {dependent types,functional reactive pro-,gramming,linear-time temporal logic},
   title = {LTL types FRP: linear-time temporal logic propositions as types, proofs as functional reactive programs},
   year = {2012},
}
@article{Stolarek2015,
   abstract = {Haskell, as implemented by the Glasgow Haskell Compiler (GHC), allows expressive type-level programming. The most popular type-level programming extension is TypeFamilies, which allows users to write functions on types. Yet, using type functions can cripple type inference in certain situations. In particular, lack of injectivity in type functions means that GHC can never infer an instantiation of a type variable appearing only under type functions. In this paper, we describe a small modification to GHC that allows type functions to be annotated as injective. GHC naturally must check validity of the injectivity annotations. The algorithm to do so is surprisingly subtle. We prove soundness for a simplification of our algorithm, and state and prove a completeness property, though the algorithm is not fully complete. As much of our reasoning surrounds functions defined by a simple pattern-matching structure, we believe our results extend beyond just Haskell. We have implemented our solution on a branch of GHC and plan to make it available to regular users with the next stable release of the compiler.},
   author = {Jan Stolarek and Simon Peyton Jones and Richard A. Eisenberg},
   doi = {10.1145/2887747.2804314},
   isbn = {9781450338080},
   issn = {03621340},
   issue = {12},
   journal = {ACM SIGPLAN Notices},
   title = {Injective type families for Haskell},
   volume = {50},
   year = {2015},
}
@inproceedings{Dunfield2014,
   abstract = {Designing and implementing typed programming languages is hard. Every new type system feature requires extending the metatheory and implementation, which are often complicated and fragile. To ease this process, we would like to provide general mechanisms that subsume many different features. In modern type systems, parametric polymorphism is fundamental, but intersection polymorphism has gained little traction in programming languages. Most practical intersection type systems have supported only refinement intersections, which increase the expressiveness of types (more precise properties can be checked) without altering the expressiveness of terms; refinement intersections can simply be erased during compilation. In contrast, unrestricted intersections increase the expressiveness of terms, and can be used to encode diverse language features, promising an economy of both theory and implementation. We describe a foundation for compiling unrestricted intersection and union types: an elaboration type system that generates ordinary lambda-calculus terms. The key feature is a Forsythe-like merge construct. With this construct, not all reductions of the source program preserve types; however, we prove that ordinary call-by-value evaluation of the elaborated program corresponds to a type-preserving evaluation of the source program. We also describe a prototype implementation and applications of unrestricted intersections and unions: records, operator overloading, and simulating dynamic typing.},
   author = {Joshua Dunfield},
   doi = {10.1017/S0956796813000270},
   isbn = {9781450310543},
   issn = {14697653},
   issue = {2-3},
   journal = {Journal of Functional Programming},
   title = {Elaborating intersection and union types},
   volume = {24},
   year = {2014},
}
@article{Dunfield2016,
   abstract = {Bidirectional typechecking, in which terms either synthesize a type or are checked against a known type, has become popular for its scalability, its error reporting, and its ease of implementation. Following principles from proof theory, bidirectional typing can be applied to many type constructs. The principles underlying a bidirectional approach to indexed types (generalized algebraic datatypes) are less clear. Building on proof-theoretic treatments of equality, we give a declarative specification of typing based on focalization. This approach permits declarative rules for coverage of pattern matching, as well as support for first-class existential types using a focalized subtyping judgment. We use refinement types to avoid explicitly passing equality proofs in our term syntax, making our calculus close to languages such as Haskell and OCaml. An explicit rule deduces when a type is principal, leading to reliable substitution principles for a rich type system with significant type inference. We also give a set of algorithmic typing rules, and prove that it is sound and complete with respect to the declarative system. The proof requires a number of technical innovations, including proving soundness and completeness in a mutually-recursive fashion.},
   author = {Joshua Dunfield and Neelakantan R. Krishnaswami},
   doi = {10.1145/2500365.2500582},
   isbn = {9781450323260},
   issn = {15232867},
   title = {Sound and Complete Bidirectional Typechecking for Higher-Rank Polymorphism with Existentials and Indexed Types},
   year = {2016},
}
@article{Orchard2014,
   abstract = {Monads are now an everyday tool in functional programming for abstracting and delimiting effects. The link between monads and effect systems is well-known, but in their typical use, monads provide a much more coarse-grained view of effects. Effect systems capture fine-grained information about the effects, but monads provide only a binary view: effectful or pure. Recent theoretical work has unified fine-grained effect systems with monads using a monad-like structure indexed by a monoid of effect annotations (called parametric effect monads). This aligns the power of monads with the power of effect systems. This paper leverages recent advances in Haskell's type system (as provided by GHC) to embed this approach in Haskell, providing user-programmable effect systems. We explore a number of practical examples that make Haskell even better and safer for effectful programming. Along the way, we relate the examples to other concepts, such as Haskell's implicit parameters and coeffects.},
   author = {Dominic Orchard and Tomas Petricek},
   doi = {10.1145/2633357.2633368},
   isbn = {9781450330411},
   issn = {0362-1340},
   issue = {Section 9},
   journal = {Haskell '14 Proceedings of the 2014 ACM SIGPLAN symposium on Haskell},
   title = {Embedding effect systems in Haskell},
   year = {2014},
}
@book{Harper2016,
   abstract = {This is a working draft of a book on the foundations of programming languages. The central organizing principle of the book is that programming language features may be seen as manifestations of an underlying type structure that governs its syntax and semantics. The emphasis, therefore, is on the concept of type, which codifies and organizes the computational universe in much the same way that the concept of set may be seen as an organizing principle for the mathematical universe. The purpose of this book is to explain this remark.},
   author = {Robert Harper},
   doi = {10.1017/CBO9781316576892},
   isbn = {9781316576892},
   issn = {15232867},
   journal = {Practical Foundations for Programming Languages, Second Edition},
   title = {Practical foundations for programming languages, second edition},
   year = {2016},
}
@inproceedings{,
   abstract = {The machine learning community has recently shown a lot of inter-est in practical probabilistic programming systems that target the problem of Bayesian inference. Such systems come in different forms, but they all express probabilistic models as computational processes using syntax resembling programming languages. In the functional programming community monads are known to offer a convenient and elegant abstraction for programming with probabil-ity distributions, but their use is often limited to very simple in-ference problems. We show that it is possible to use the monad abstraction to construct probabilistic models for machine learning, while still offering good performance of inference in challenging models. We use a GADT as an underlying representation of a prob-ability distribution and apply Sequential Monte Carlo-based meth-ods to achieve efficient inference. We define a formal semantics via measure theory. We demonstrate a clean and elegant implementa-tion that achieves performance comparable with Anglican, a state-of-the-art probabilistic programming system.},
   author = {Adam Ścibior and Zoubin Ghahramani and Andrew D. Gordon},
   doi = {10.1145/2804302.2804317},
   isbn = {9781450338080},
   issn = {03621340},
   journal = {Proceedings of the 8th ACM SIGPLAN Symposium on Haskell - Haskell 2015},
   title = {Practical probabilistic programming with monads},
   year = {2015},
}
@article{Petricek2014,
   abstract = {The notion of context in functional languages no longer refers just to variables in scope. Context can capture additional properties of variables (usage patterns in linear logics; caching requirements in dataflow languages) as well as additional resources or properties of the execution environment (rebindable resources; platform version in a cross-platform application). The recently introduced notion of coeffects captures the latter, whole-context properties, but it failed to capture fine-grained per-variable properties. We remedy this by developing a generalized coeffect system with annotations indexed by a coeffect shape. By instantiating a concrete shape, our system captures previously studied flat (whole-context) coeffects, but also structural (per-variable) coeffects, making coeffect analyses more useful. We show that the structural system enjoys desirable syntactic properties and we give a categorical semantics using extended notions of indexed comonad. The examples presented in this paper are based on analysis of established language features (liveness, linear logics, dataflow, dynamic scoping) and we argue that such context-aware properties will also be useful for future development of languages for increasingly heterogeneous and distributed platforms.},
   author = {Tomas Petricek and Dominic Orchard and Alan Mycroft},
   doi = {10.1145/2628136.2628160},
   isbn = {9781450328739},
   issn = {0362-1340},
   journal = {Proceedings of the 19th ACM SIGPLAN international conference on Functional programming - ICFP '14},
   title = {Coeffects: A calculus of context-dependent computation},
   year = {2014},
}
@inproceedings{Chang2017,
   abstract = {We present TURNSTILE, a metalanguage for creating typed embedded languages. To implement the type system, pro-grammers write type checking rules resembling traditional judgment syntax. To implement the semantics, they incorpo-rate elaborations into these rules. TURNSTILE critically de-pends on the idea of linguistic reuse. It exploits a macro sys-tem in a novel way to simultaneously type check and rewrite a surface program into a target language. Reusing a macro system also yields modular implementations whose rules may be mixed and matched to create other languages. Com-bined with typical compiler and runtime reuse, TURNSTILE produces performant typed languages with little effort.},
   author = {Stephen Chang and Alex Knauth and Ben Greenman},
   doi = {10.1145/3009837.3009886},
   isbn = {9781450346603},
   issn = {07308566},
   journal = {Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages - POPL 2017},
   title = {Type systems as macros},
   year = {2017},
}
@inproceedings{Cave2014,
   abstract = {Functional Reactive Programming (FRP) models reactive systems with events and signals, which have previously been observed to correspond to the “eventually” and “always” modalities of linear temporal logic (LTL). In this paper, we define a constructive vari- ant of LTL with least fixed point and greatest fixed point opera- tors in the spirit of the modal mu-calculus, and give it a proofs-as- programs interpretation as a foundational calculus for reactive programs. Previous work emphasized the propositions-as-types part of the correspondence between LTL and FRP; here we emphasize the proofs-as-programs part by employing structural proof theory. We show that the type system is expressive enough to enforce liveness properties such as the fairness of schedulers and the eventual de- livery of results. We illustrate programming in this calculus using (co)iteration operators. We prove type preservation of our opera- tional semantics, which guarantees that our programs are causal. We give also a proof of strong normalization which provides justi- fication that our programs are productive and that they satisfy liveness properties derived from their types.},
   author = {Andrew Cave and Brigitte Pientka},
   doi = {10.1145/2535838.2535881},
   isbn = {978-1-4503-2544-8},
   issn = {15232867},
   journal = {POPL '14:Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
   title = {Fair Reactive Programming},
   year = {2014},
}
@article{Dhulipala2017,
   abstract = {Existing graph-processing frameworks let users develop efficient im-plementations for many graph problems, but none of them support efficiently bucketing vertices, which is needed for bucketing-based graph algorithms such as ∆-stepping and approximate set-cover. Motivated by the lack of simple, scalable, and efficient implemen-tations of bucketing-based algorithms, we develop the Julienne framework, which extends a recent shared-memory graph process-ing framework called Ligra with an interface for maintaining a collection of buckets under vertex insertions and bucket deletions. We provide a theoretically efficient parallel implementation of our bucketing interface and study several bucketing-based algo-rithms that make use of it (either bucketing by remaining degree or by distance) to improve performance: the peeling algorithm for k-core (coreness), ∆-stepping, weighted breadth-first search, and approximate set cover. The implementations are all simple and con-cise (under 100 lines of code). Using our interface, we develop the first work-efficient parallel algorithm for k-core in the literature with nontrivial parallelism. We experimentally show that our bucketing implementation scales well and achieves high throughput on both synthetic and real-world workloads. Furthermore, the bucketing-based algorithms written in Julienne achieve up to 43x speedup on 72 cores with hyper-threading over well-tuned sequential baselines, significantly outperform existing work-inefficient implementations in Ligra, and either outperform or are competitive with existing special-purpose parallel codes for the same problem. We experimentally study our implementations on the largest publicly available graphs and show that they scale well in practice, processing real-world graphs with billions of edges in seconds, and hundreds of billions of edges in a few minutes. As far as we know, this is the first time that graphs at this scale have been analyzed in the main memory of a single multicore machine.},
   author = {Laxman Dhulipala and Guy Blelloch and Julian Shun},
   doi = {10.1145/3087556.3087580},
   isbn = {9781450345934},
   journal = {Spaa},
   title = {Julienne: A Framework for Parallel Graph Algorithms using Work-efficient Bucketing},
   year = {2017},
}
@inproceedings{Blelloch2016,
   abstract = {In this paper we show that most sequential randomized incremental algorithms are in fact parallel. We consider several random incremental algorithms including algorithms for comparison sorting and Delaunay triangulation; linear programming, closest pair, and smallest enclosing disk in constant dimensions; as well as least-element lists and strongly connected components on graphs. We analyze the dependence between iterations in an algorithm, and show that the dependence structure is shallow for all of the algorithms, implying high parallelism. We identify three types of dependences found in the algorithms studied and present a framework for analyzing each type of algorithm. Using the framework gives work-efficient polylogarithmic-depth parallel algorithms for most of the problems that we study. Some of these algorithms are straightforward (e.g., sorting and linear programming), while others are more novel and require more effort to obtain the desired bounds (e.g., Delaunay triangulation and strongly connected components). The most surprising of these results is for planar Delaunay triangulation for which the incremental approach is by far the most commonly used in practice, but for which it was not previously known whether it is theoretically efficient in parallel.},
   author = {Guy E. Blelloch and Yan Gu and Julian Shun and Yihan Sun},
   doi = {10.1145/2935764.2935766},
   isbn = {9781450342100},
   journal = {Proceedings of the 28th ACM Symposium on Parallelism in Algorithms and Architectures - SPAA '16},
   title = {Parallelism in Randomized Incremental Algorithms},
   year = {2016},
}
@thesis{Cheung2018,
   abstract = {While monadic effects are widespread in modern functional program- ming, the idea of formulating computational effects as algebraic theories seems a less familiar one to programmers. One appealing feature of such algebraic effects is the clear decoupling between specification and implemen- tation (or in more model-theoretic terms, syntax versus semantics). With monads, this distinction is arguably less clear. But perhaps the most compelling reason for considering algebraic effects is the relative ease by which such effects can be combined. This point is clearly of much relevance to the semantics of programming languages since in much of modern software development, one often deals with multiple interacting effects. As a simple example, we may want a program that not only keeps track of some state across the computation (e.g. a parser consuming a string of text), but also account for the possibility of failure. In Haskell, we can express the combination of “state” and “exception” as itself a monadic type. But it is well known that there is more than one way to combine these two effects, each corresponding to a different composition of the underlying functors. One choice of composition reverts the state to its original value in the event of a failure, whereas another choice of composition does not. Neither can be considered canonical, since both have their use cases. It turns out that under the lens of algebraic effects, both interactions can be understood in terms of straightforward amalgamations of the respective equational laws. Specifically, the latter is given by taking a simple union of the two theories, while the former in addition demands equations for commutativity between each pair of stateful and exceptional operations. Both of these constructions arise naturally from the categorical structure of Lawvere theories—the more abstract formulation of equational theories, as categories. In this dissertation we seek to further the understanding of combining effects, especially from this more algebraic perspective. Of particular inter- est is a distributive tensor construction on Lawvere theories that does not seem to be very widely known. Similar to the above, this takes a simple union of two theories, but demands additional equations for distributivity of operations in one theory over those of the other (e.g. in the same sense that multiplication distributes over addition in any ring-like algebraic structure). There are some clear parallels between this notion and distributive laws of monads (that underlie several of the most common monad transformers). We make some steps towards establishing a more precise relationship, giv- ing examples where the two notions coincide. The distributive tensor plays a leading role in many examples of computational interest—two such appli- cations will be considered here in some depth. From the observation that various combinatorial search strategies are characterised by two equivalent formulations—as bunch monadic types, and as more structured theories of monoids—we give a number of correspondence results. In particular, the bunch type describing a kind of depth-bounded traversal is shown to be models of a distributive tensor. We also consider the free models of this theory, giving rise to a monad, and by imposing sym- metry on the monoid operation, obtain another distributive tensor theory matching closely breadth-first traversal. Depth-first traversal is implicit in the list monad, and it is shown that the list monad transformer is exactly a distributive tensor from the theory of monoids. This is in contrast to the equational presentation of the alternative “done right” list transformer, which is clarified: while it too exhibits distributivity of the monoid opera- tion, it does so crucially only in the leftwards direction and not the right. The second application considers in some detail a derivation of the ge- ometrically convex monad—the combination of probabilistic and nondeter- ministic choice effects, called combined choice—in a relatively simpler setting than the usual domain-theoretic presentation. As such, its characterisation as a distributive tensor is clearer. The results building up to this are then applied to equational reasoning. Under this lens, one is more able to iden- tify an incorrect assumption in various equational axiomatisations of effects (such as probabilistic choice) overlooked in the literature. As it is no easy task to capture the equational properties between probabilistic and nonde- terministic choice, a technique is explored for reasoning about such equations visually by taking a geometric interpretation of the free models of combined choice, as convex polygons on a plane.},
   author = {Kwok-Ho Cheung},
   institution = {Merton College; University of Oxford},
   pages = {206},
   title = {Distributive Interaction of Algebraic Effects},
   url = {https://ora.ox.ac.uk/objects/uuid:66106628-0a71-4564-bc34-c398db766818/download_file?file_format=pdf&safe_filename=report.pdf&type_of_work=Thesis},
   year = {2018},
}
@article{Blelloch1996,
   abstract = {In the past 20 years there have been a huge number of algorithms designed for parallel computers, most which have been designed for one of the variants of the Parallel Random Access Machine (PRAM) model. Unfortunately there has been limited progress in getting practical implementations of the algorithms on any real parallel machine. Although discrepancies between the PRAM model and actual implementations of parallel machines (particularly as regards communication costs) has played a part in this lack of progress, another significant problem is the lack of good programming languages. With the languages that come with existing parallel machines it can be a major project to implement a simple algorithm, and once implemented the code is unlikely to port to any other parallel machine. This paper describes a data-parallel language, Nesl, designed for programming parallel algorithms. Nesl currently runs on the Connection Machine CM-2 and the Cray Y-MP, and generates reasonably efficient cod...},
   author = {Guy E. Blelloch},
   doi = {10.1145/227234.227246},
   issn = {00010782},
   journal = {Communications of the ACM},
   title = {Programming parallel algorithms},
   year = {1996},
}
@inproceedings{Smith2010,
   abstract = {This paper explores a method for analyzing the expressive range of a procedural level generator, and applies this method to Launchpad, a level generator for 2D platformers. Instead of focusing on the number of levels that can be created or the amount of time it takes to create them, we instead examine the variety of generated levels and the impact of changing input parameters. With the rise in the popularity of PCG, it is important to be able to fairly evaluate and compare different generation techniques within similar domains. We have found that such analysis can also expose unexpected biases in the generation algorithm and holes in the expressive range that drive future work},
   author = {Gillian Smith and Jim Whitehead},
   doi = {10.1145/1814256.1814260},
   isbn = {9781450300230},
   journal = {Proceedings of the 2010 Workshop on Procedural Content Generation in Games - PCGames '10},
   title = {Analyzing the expressive range of a level generator},
   year = {2010},
}
@book_section{Day1970,
   author = {Brian Day},
   doi = {10.1007/BFb0060438},
   pages = {1-38},
   publisher = {Springer, Berlin, Heidelberg},
   title = {On closed categories of functors},
   url = {http://link.springer.com/10.1007/BFb0060438},
   year = {1970},
}
@article{Wadler2003,
   abstract = {Gifford and others proposed an effect typing discipline to delimit the scope of computational effects within a program, while Moggi and others proposed monads for much the same purpose. Here we marry effects to monads, uniting two previously separate lines of research. In particular, we show that the type, region, and effect system of Talpin and Jouvelot carries over directly to an analogous system for monads, including a type and effect reconstruction algorithm. The same technique should allow one to transpose any effect system into a corresponding monad system.},
   author = {Philip; Wadler and Peter Thiemann},
   doi = {10.1145/601775.601776},
   isbn = {1-58113-024-4},
   issn = {15293785},
   journal = {ACM Transactions on Computational Logic},
   title = {The marriage of effects and monads},
   year = {2003},
}
@article{Swierstra2008,
   abstract = {This paper describes a technique for assembling both data types and functions from isolated individual components. We also explore how the same technology can be used to combine free monads and, as a result, structure Haskell’s monolithic IO monad.},
   author = {W Swierstra},
   doi = {10.1017/S0956796808006758},
   isbn = {1469-7653},
   issn = {0956-7968},
   journal = {Journal of Functional Programming},
   title = {Data types à la carte},
   year = {2008},
}
@article{Plotkin2003,
   abstract = {Given a complete and cocomplete symmetric monoidal closed category V and a symmetric monoidal V-category C with cotensors and a strong V-monad T on C, we investigate axioms under which an Ob C-indexed family of operations of the form α x :(Tx) v →(Tx) w provides semantics for algebraic operations on the computational λ-calculus. We recall a definition for which we have elsewhere given adequacy results, and we show that an enrichment of it is equivalent to a range of other possible natural definitions of algebraic operation. In particular, we define the notion of generic effect and show that to give a generic effect is equivalent to giving an algebraic operation. We further show how the usual monadic semantics of the computational λ-calculus extends uniformly to incorporate generic effects. We outline examples and non-examples and we show that our definition also enriches one for call-by-name languages with effects.},
   author = {Gordon Plotkin and John Power},
   doi = {10.1023/A:1023064908962},
   isbn = {9783642157202},
   issn = {09272852},
   journal = {Applied Categorical Structures},
   keywords = {Algebraic operation,Computational effect,Lawvere theory,Monad},
   pmid = {1284},
   title = {Algebraic operations and generic effects},
   year = {2003},
}
@article{Blelloch1989,
   abstract = {A study of the effects of adding two scan primitives as unit-time primitives to PRAM (parallel random access machine) models is presented. It is shown that the primitives improve the asymptotic running time of many algorithms by an O(log n) factor, greatly simplifying the description of many algorithms, and are significantly easier to implement than memory references. It is argued that the algorithm designer should feel free to use these operations as if they were as cheap as a memory reference. The author describes five algorithms that clearly illustrate how the scan primitives can be used in algorithm design: a radix-sort algorithm, a quicksort algorithm, a minimum-spanning-tree algorithm, a line-drawing algorithm, and a merging algorithm. These all run on an EREW (exclusive read, exclusive write) PRAM with the addition of two scan primitives and are either simpler or more efficient than their pure PRAM counterparts. The scan primitives have been implemented in microcode on the Connection Machine system, are available in PARIS (the parallel instruction set of the machine)},
   author = {Guy E. Blelloch},
   doi = {10.1109/12.42122},
   isbn = {0018-9340},
   issn = {00189340},
   journal = {IEEE Transactions on Computers},
   keywords = {Connection Machine,PRAM,parallel algorithms,parallel computing,prefix computations,scan},
   title = {Scans as Primitive Parallel Operations},
   year = {1989},
}
@newspaper_article{RIVAS2017,
   abstract = {There are different notions of computation, the most popular being monads, applicative functors, and arrows. In this article we show that these three notions can be seen as monoids in a monoidal category. We demonstrate that at this level of abstraction one can obtain useful results which can be instantiated to the different notions of computation. In particular, we show how free constructions and Cayley representations for monoids translate into useful constructions for monads, applicative functors, and arrows. Moreover, the uniform presentation of all three notions helps in the analysis of the relation between them.},
   author = {EXEQUIEL RIVAS and MAURO JASKELIOFF},
   doi = {10.1017/S0956796817000132},
   issn = {14697653},
   journal = {Journal of Functional Programming},
   title = {Notions of computation as monoids*},
   year = {2017},
}
@web_page{Grenrus2018,
   abstract = {I define free Monad and free Applicative using single type, parametrised over a tensor. It's possible, because both Monad and Applicative are monoids in the category of endofunctors. There is little, if any, practical applications I can foresee for these definitions, but it's fun to see how things are connected. I won't prove laws hold, or constructions are free (= are left adjoint of a forgetful functor).},
   author = {Oleg Grenrus},
   title = {Free Monad and Free Applicative using single Free type},
   url = {http://oleg.fi/gists/posts/2018-02-21-single-free.html},
   year = {2018},
}
@article{Goguen1977,
   abstract = {Many apparently divergent approaches to specifying formal semantics of programming languages are applications of initial algebra semantics. In this paper an overview of initial algebra semantics is provided. The major technical feature is an initial continuous algebra which permits unified algebraic treatment of iterative and recursive semantic features in the same framework as more basic operations.},
   author = {J. A. Goguen and J. W. Thatcher and E. G. Wagner and J. B. Wright},
   doi = {10.1145/321992.321997},
   issn = {00045411},
   journal = {Journal of the ACM},
   title = {Initial Algebra Semantics and Continuous Algebras},
   year = {1977},
}
@article{Hoare1997,
   abstract = {Professional practice in a mature engineering discipline is based on relevant scientific theories, usually expressed in the language of mathematics. A mathematical theory of programming aims to provide a similar basis for specification, design and implementation of computer programs. The theory can be presented in a variety of styles, including l. Denotational, relating a program to a specification of its observable properties and behaviour. 2. Algebraic, providing equations and inequations for comparison, transformation and optimisation of designs and programs. 3. Operational, describing individual steps of a possible mechanical implementation. This paper presents simple theories of sequential non-deterministic programming in each of these three styles; by deriving each presentation from its predecessor in a cyclic fashion, mutual consistency is assured.},
   author = {Tony Hoare},
   doi = {10.1007/978-3-319-14806-9},
   isbn = {3-540-63195-X},
   journal = {Mathematical methods in program development. NATO ASI Series F Computer and Systems Science},
   keywords = {algebraic,denotational,non-determinism,operational,programming,programming methods,semantics},
   title = {Unified theories of programming},
   year = {1997},
}
@article{Mcbride2008,
   abstract = {In this paper, we introduce Applicative functors—an abstract characterisation of an ap- plicative style of effectful programming, weaker than Monads and hence more widespread. Indeed, it is the ubiquity of this programming pattern that drew us to the abstraction. We retrace our steps in this paper, introducing the applicative pattern by diverse exam- ples, then abstracting it to define the Applicative type class and introducing a bracket notation which interprets the normal application syntax in the idiom of an Applicative functor. Further, we develop the properties of applicative functors and the generic opera- tions they support.We close by identifying the categorical structure of applicative functors and examining their relationship both with Monads and with Arrows.},
   author = {Conor Mcbride and Ross Paterson},
   doi = {10.1017/S0956796807006326},
   isbn = {0956-7968},
   issn = {09567968},
   journal = {Journal of Functional Programming},
   title = {Applicative programming with effects},
   year = {2008},
}
@inproceedings{Gibbons2011,
   abstract = {One of the appeals of pure functional programming is that it is so amenable to equational reasoning. One of the problems of pure functional programming is that it rules out computational effects. Moggi and Wadler showed how to get round this problem by using monads to encapsulate the effects, leading in essence to a phase distinction - a pure functional evaluation yielding an impure imperative computation. Still, it has not been clear how to reconcile that phase distinction with the continuing appeal of functional programming; does the impure imperative part become inaccessible to equational reasoning? We think not; and to back that up, we present a simple axiomatic approach to reasoning about programs with computational effects.},
   author = {Jeremy Gibbons and Ralf Hinze},
   doi = {10.1145/2034773.2034777},
   isbn = {9781450308656},
   issn = {03621340},
   journal = {Proceeding of the 16th ACM SIGPLAN international conference on Functional programming - ICFP '11},
   title = {Just do it},
   year = {2011},
}
@article{Gibbons2011,
   abstract = {One of the appeals of pure functional programming is that it is so amenable to equational reasoning. One of the problems of pure functional programming is that it rules out computational effects. Moggi and Wadler showed how to get round this problem by using monads to encapsulate the effects, leading in essence to a phase distinction - a pure functional evaluation yielding an impure imperative computation. Still, it has not been clear how to reconcile that phase distinction with the continuing appeal of functional programming; does the impure imperative part become inaccessible to equational reasoning? We think not; and to back that up, we present a simple axiomatic approach to reasoning about programs with computational effects.},
   author = {Jeremy Gibbons},
   doi = {10.1145/2034574.2034777},
   isbn = {9781450308656},
   issn = {0362-1340},
   journal = {International conference on Functional programming, ACM SIGPLAN},
   keywords = {alge-,braic specification,equational reasoning,lawvere theories,monads},
   title = {Just do it: Simple monadic equational reasoning},
   year = {2011},
}
@inproceedings{,
   abstract = {We present a new model, based on monads, for performing input/output in a non-strict, purely functional language. It is composable, extensible, efficient, requires no extensions to the type system, and extends smoothly to incorporate mixed-language working and in-place array updates.},
   author = {Simon L. Peyton Jones and Philip Wadler},
   doi = {10.1145/158511.158524},
   isbn = {0897915607},
   issn = {03600300},
   journal = {Proceedings of the 20th ACM SIGPLAN-SIGACT symposium on Principles of programming languages  - POPL '93},
   pmid = {20698430},
   title = {Imperative functional programming},
   year = {1993},
}
@generic{,
   abstract = {We exhibit a set of functions coded in Haskell that can be used as building blocks to construct a variety of interpreters for Lisp-like languages. The building blocks are joined merely through functional composition. Each building block contributes code to support a specific feature, such as numbers, continuations, functions calls, or nondeterminism. The result of composing some number of building blocks is a parser, an interpreter, and a printer that support exactly the expression forms and data types needed for the combined set of features, and no more. The data structures are organized as pseudomonads, a generalization of monads that allows composition. Functional composition of the building blocks implies type composition of the relevant pseudomonads. Our intent was that the Haskell type resolution system ought to be able to deduce the appropriate data types automatically. Unfortunately there is a deficiency in current Haskell implementations related to recursive data types: circularity must be reflected statically in the type definitions. We circumvent this restriction by applying a purpose-built program simplifier that performs partial evaluation and a certain amount of program algebra. We construct a wide variety of interpreters in the style of Wadler by starting with the building blocks and a page of boiler-plate code, writing three lines of code (one to specify the building blocks and two to (redundantly) specify type compositions), and then applying the simplifier. The resulting code is acceptable Haskell code. We have tested a dozen different interpreters with various combinations of features. In this paper we discuss the overall code structuring strategy, exhibit several building blocks, briefly describe the partial evaluator, and present a number of automatically generated interpreters.},
   author = {Guy Lewis Steele Jr.},
   doi = {10.1145/174675.178068},
   isbn = {0-89791-636-0},
   issn = {07308566},
   journal = {Proceedings of the 21st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
   title = {Building interpreters by composing monads},
   year = {1994},
}
@article{Benton1996,
   abstract = {Models of intuitionistic linear logic also provide models of\nMoggi's computational metalanguage. We use the adjoint presentation of\nthese models and the associated adjoint calculus to show that three\ntranslations, due mainly to Moggi, of the lambda calculus into the\ncomputational metalanguage (direct, call-by-name and call-by-value)\ncorrespond exactly to three translations, due mainly to Girard, of\nintuitionistic logic into intuitionistic linear logic. We also consider\nextending these results to languages with recursion},
   author = {Nick Benton and Philip Wadler},
   doi = {10.1109/LICS.1996.561458},
   isbn = {0-8186-7463-6},
   issn = {1043-6871},
   journal = {Proceedings 11th Annual IEEE Symposium on Logic in Computer Science},
   title = {Linear logic, monads and the lambda calculus},
   year = {1996},
}
@article{Wadler1994,
   abstract = {Moggi's use of monads to factor semantics is used to model the composable continuations of Danvy and Filinski. This yields some insights into the type systems proposed by Murthy and by Danvy and Filinski. Interestingly, modelling some aspects of composable continuations requires a structure that is almost, but not quite, a monad.},
   author = {Philip Wadler},
   doi = {10.1007/BF01019944},
   issn = {08924635},
   journal = {LISP and Symbolic Computation},
   keywords = {Continuation-passing style,Continuations,Monads,Types},
   title = {Monads and composable continuations},
   year = {1994},
}
@article{Lindley2010,
   abstract = {Abstract We introduce the arrow calculus , a metalanguage for manipulating Hughes's arrows with close relations both to Moggi's metalanguage for monads and to Paterson's arrow notation. Arrows are classically defined by extending lambda calculus with three ... \n},
   author = {Sam Lindley and Philip Wadler and Jeremy Yallop},
   doi = {10.1017/S095679680999027X},
   issn = {09567968},
   journal = {Journal of Functional Programming},
   title = {The arrow calculus},
   year = {2010},
}
@article{King1992,
   abstract = {Monads provide a way of structuring functional programs. Most real applications require a combination of primitive monads. Here we describe how some monads may be combined with others to yield a combined monad.},
   author = {David J King and Philip Wadler},
   doi = {10.1007/978-1-4471-3215-8_12},
   isbn = {3540198202},
   journal = {Proceedings of the 1992 Glasgow Workshop on Functional Programming},
   title = {Combining Monads},
   year = {1992},
}
@article{Lindley2011,
   abstract = {We revisit the connection between three notions of computation: Moggi s monads, Hughes s arrows and McBride and Paterson s idioms (also called applicative functors). We show that idioms are equivalent to arrows that satisfy the type isomorphism A→B 1→(A→B) and that monads are equivalent to arrows that satisfy the type isomorphism A→B←A→(1→B). Further, idioms embed into arrows and arrows embed into monads. © 2011 Elsevier B.V. All rights reserved.},
   author = {Sam Lindley and Philip Wadler and Jeremy Yallop},
   doi = {10.1016/j.entcs.2011.02.018},
   issn = {15710661},
   journal = {Electronic Notes in Theoretical Computer Science},
   keywords = {applicative functors,arrows,idioms,monads},
   title = {Idioms are oblivious, arrows are meticulous, monads are promiscuous},
   year = {2011},
}
@inproceedings{Wadler1992,
   abstract = {This paper explores the use [of] monads to structure functional programs. No prior knowledge of monads or category theory is required. Monads increase the ease with which programs may be modified. They can mimic the effect of impure features such as exceptions, state, and continuations; and also provide effects not easily achieved with such features. The types of a program reflect which effects occur. The first section is an extended example of the use of monads. A simple interpreter is modified to support various extra features: error messages, state, output, and non-deterministic choice. The second section describes the relation between monads and continuation-passing style. The third section sketches how monads are used in a compiler for Haskell that is written in Haskell.},
   author = {Philip Wadler},
   doi = {10.1145/143165.143169},
   isbn = {0897914538},
   issn = {1573286X},
   journal = {Proceedings of the 19th ACM SIGPLAN-SIGACT symposium on Principles of programming languages  - POPL '92},
   pmid = {21349828},
   title = {The essence of functional programming},
   year = {1992},
}
@article{Wadler1992,
   abstract = {Category theorists invented monads in the 1960's to concisely express certain aspects of universal algebra. Functional programmers invented list comprehensions in the 1970's to concisely express certain programs involving lists. This paper shows how list comprehensions may be generalised to an arbitrary monad, and how the resulting programming feature can concisely express in a pure functional language some programs that manipulate state, handle exceptions, parse text, or invoke continuations. A new solution to the old problem of destructive array update is also presented. No knowledge of category theory is assumed.},
   author = {Philip Wadler},
   doi = {10.1017/S0960129500001560},
   isbn = {089791368X},
   issn = {14698072},
   journal = {Mathematical Structures in Computer Science},
   title = {Comprehending monads},
   year = {1992},
}
@article{Hughes2000,
   abstract = {Monads have become very popular for structuring functional programs since Wadler introduced their use in 1990. In particular, libraries of combinators are often based on a monadic type. Such libraries share (in part) a common interface, from which numerous benefits flow, such as the possibility to write generic code which works together with any library. But, several interesting and useful libraries are fundamentally incompatible with the monadic interface. In this paper I propose a generalization of monads, which I call arrows, with significantly wider applicability. The paper shows how many of the techniques of monadic programming generalize to the new setting, and gives examples to show that the greater generality is useful. In particular, three non-monadic libraries for efficient parsing, building graphical user interfaces, and programming active web pages fit naturally into the new framework.},
   author = {John Hughes},
   doi = {10.1016/S0167-6423(99)00023-4},
   isbn = {9788578110796},
   issn = {01676423},
   journal = {Science of Computer Programming},
   pmid = {350516},
   title = {Generalizing monads to arrows},
   year = {2000},
}
@book{Pearson2011,
   abstract = {"Digital design/programming"--Page 4 of cover. Includes index. Describes the principles of algorithmic art along with examples of generative art and tutorials using the processing programming language to create the images found in the book. Introduction : The organic vs. the mechanical : Generative art is easy ; Order and chaos ; Programming as poetry ; The chaos artist -- Part 1. Creative coding : 1. Generative art: in theory and practice : Not your father's art form -- The history of a new idea -- The digital toolset : Perpetual impermanence ; The latest in primitive technology -- Processing: a programming language for artists : What is processing? : Bold strides and baby steps ; Hello world -- Programmatic drawing : Functions, parameters, and color values ; Strokes, styles and co-ordinates ; Variables ; Fills, alpha values, and drawing order -- Structure, logic, and animation : The frame loop ; Writing your own functions ; Operators ; Conditionals -- Looping : While loops ; Leaving traces ; For loops -- Saving, publishing, and distributing your work : Version control ; Creating stills ; Using a still as an alt image ; Creating video ; Frame rates and screen sizes ; Mobile devices, iPhone/iPad, and Android -- Part 2. Randomness and noise : 3. The wrong way to draw a line : Randomness and not-so-randomness -- Iterative variance -- Naturalistic variance : Perlin noise in processing ; Creating your own noise ; A custom random function -- 4. The wrong way to draw a circle : Rotational drawing : Drawing your first circle ; Turning a circle into a spiral ; Noisy Spirals ; Creating your own noise, revisited -- Case study: wave clock -- 5. Adding dimensions : Two-dimensional noise : Creating a noise grid ; Noise visualizations -- Noisy animation -- The third dimension : Drawing in 3D space ; Three-dimensional noise ; The wrong way to draw a sphere -- Part 3. Complexity : 6. Emergence : Emergence defined : Ant colonies and flocking algorithms ; Think locally, act locally -- Object-oriented programming : Classes and instances ; Local knowledge (collision detection) ; Interaction patterns -- 7. Autonomy : Cellular automata : Setting up the framework ; The game of life ; Vichniac vote ; Brian's brain ; Waves (averaging) -- Simulation and visualization : Software agents ; Human agents -- Fractals : Infinite recursion -- Coding self-similarity : Trunks and branches ; Animating your tree -- Exponential growth -- Case study: Sutcliffe pentagons : Construction ; Exploration.},
   author = {Matt. Pearson},
   isbn = {9781935182627},
   pages = {197},
   publisher = {Manning},
   title = {Generative art : a practical guide using processing},
   url = {https://www.manning.com/books/generative-art?},
   year = {2011},
}
@article{Galanter2003,
   abstract = {In this paper an attempt is made to offer a definition of generative art that is inclusive and provides fertile ground for both technical and art theoretical development. First the use of systems is identified as a key element in generative art. Various ideas from complexity theory are then introduced. It is noted that systems exist on a continuum from the highly ordered to the highly disordered. Citing examples from information theory and complexity science, it is noted that highly ordered and highly disordered systems are typically viewed as simple, and complex systems exhibit both order and disorder. This leads to the adoption of effective complexity, order, and disorder as organizing principles in the comparison of various generative art systems. This inclusive view leads to the somewhat surprising observation that generative art is as old as art itself. A number of specific artists and studies are discussed within this systems and complexity theory influenced paradigm. Finally a number of art theoretical questions are introduced to exercise the suggested generative art definition and implicit paradigm.},
   author = {Philip Galanter},
   journal = {In GA2003–6th Generative Art Conference},
   title = {What is Generative Art? Complexity theory as a context for art theory},
   year = {2003},
}
@book{Shiffman2012,
   abstract = {How can we capture the unpredictable evolutionary and emergent properties of nature in software? How can understanding the mathematical principles behind our physical world help us to create digital worlds? This book focuses on a range of programming strategies and techniques behind computer simulations of natural systems, from elementary concepts in mathematics and physics to more advanced algorithms that enable sophisticated visual results. Readers will progress from building a basic physics engine to creating intelligent moving objects and complex systems, setting the foundation for further experiments in generative design. Subjects covered include forces, trigonometry, fractals, cellular automata, self-organization, and genetic algorithms. The book's examples are written in Processing, an open-source language and development environment built on top of the Java programming language. On the book's website (http: //www.natureofcode.com), the examples run in the browser via Processing's JavaScript mode.},
   author = {Daniel Shiffman},
   doi = {10.1017/CBO9781107415324.004},
   isbn = {978-0985930806},
   issn = {19454589},
   journal = {The Nature of Code},
   pmid = {25246403},
   title = {The Nature of Code},
   year = {2012},
}
@article{Jeltsch2016,
   abstract = {Functional reactive programming (FRP) makes it possible to express temporal aspects in a declarative way. Traditional approaches to FRP cannot handle objects like widgets in a graphical user interface or files in a file system. Therefore, programmers have to resort to ordinary methods of effectful programming when working with objects. In this paper, we devise a variant of FRP with support for objects, called “resourceful FRP”, and develop an abstract categorical semantics for this FRP variant.},
   author = {Wolfgang Jeltsch},
   doi = {10.1016/j.jlamp.2016.07.001},
   isbn = {9781450325677},
   issn = {23522216},
   journal = {Journal of Logical and Algebraic Methods in Programming},
   keywords = {Categorical semantics,Functional reactive programming,Linear logic,Logic of bunched implications,Temporal logic},
   title = {Abstract categorical semantics for resourceful functional reactive programming},
   year = {2016},
}
@article{Krishnaswami2013,
   abstract = {Functional reactive programming (FRP) is an elegant approach to declaratively specify reactive systems. However, the powerful abstractions of FRP have historically made it difficult to predict and control the resource usage of programs written in this style. In this paper, we give a new language for higher-order reactive programming. Our language generalizes and simplifies prior type systems for reactive programming, by supporting the use of streams of streams, first-class functions, and higher-order operations. We also support many temporal operations beyond streams, such as terminatable streams, events, and even resumptions with first-class schedulers. Furthermore, our language supports an efficient implementation strategy permitting us to eagerly deallocate old values and statically rule out spacetime leaks, a notorious source of inefficiency in reactive programs. Furthermore, these memory guarantees are achieved without the use of a complex substructural type discipline. We also show that our implementation strategy of eager deallocation is safe, by showing the soundness of our type system with a novel step-indexed Kripke logical relation.},
   author = {Neelakantan R. Krishnaswami},
   doi = {10.1145/2500365.2500588},
   isbn = {9781450323260},
   issn = {03621340},
   journal = {… international conference on Functional programming},
   keywords = {Functional reactive programming,Kripke logical re- lations,capabilities,comonads,dataflow,guarded recursion,temporal logic},
   title = {Higher-order functional reactive programming without spacetime leaks},
   year = {2013},
}
@article{Ploeg2015,
   abstract = {We present a new interface for practical Functional Reactive Pro- gramming (FRP) that (1) is close in spirit to the original FRP ideas, (2) does not have the original space-leak problems, without using arrows or advanced types, and (3) provides a simple and expressive way for performing I/O actions from FRP code.We also provide a denotational semantics for this new interface, and a technique (using Kripke logical relations) for reasoning about which FRP functions may “forget their past”, i.e. which functions do not have an inher- ent space-leak. Finally, we show how we have implemented this interface as a Haskell library called FRPNow.},
   author = {Atze van der Ploeg and Koen Claessen},
   doi = {10.1145/2784731.2784752},
   isbn = {9781450336697},
   issn = {0362-1340},
   journal = {Proceedings of the 20th ACM SIGPLAN International Conference on Functional Programming - ICFP 2015},
   title = {Practical principled FRP: forget the past, change the future, FRPNow!},
   year = {2015},
}
@inproceedings{Czaplicki2013,
   abstract = {Graphical user interfaces (GUIs) mediate many of our interactions with computers. Functional Reactive Programming (FRP) is a promising approach to GUI design, providing high-level, declarative, compositional abstractions to describe user interactionsa},
   author = {Evan Czaplicki and Stephen Chong},
   doi = {10.1145/2491956.2462161},
   isbn = {9781450320146},
   issn = {15232867},
   journal = {Proceedings of the 34th ACM SIGPLAN conference on Programming language design and implementation - PLDI '13},
   title = {Asynchronous functional reactive programming for GUIs},
   year = {2013},
}
@article{Czaplicki2012,
   abstract = {Graphical user interfaces (GUIs) mediate almost all of our interactions with computers, whether it is through web pages, phone apps, or desktop applications. Functional Reactive Programming (FRP) is a promising approach to GUI design. This thesis presents Elm, a concurrent FRP language focused on easily creating responsive GUIs. Elm has two major features: (1) purely functional graphical layout and (2) support for Concurrent FRP. Purely functional graphical layout is a high level framework for working with complex visual com- ponents. It makes it quick and easy to create and combine text, images, and video into rich multimedia displays. Concurrent FRP solves some of FRP's long-standing efficiency problems: global delays and needless recomputation. Together, Elm's two major features simplify the complicated task of creating responsive and usable graphical user interfaces. This thesis also includes a fully functional compiler for Elm, available at elm-lang.org. This site includes an interactive code editor that allows you to write and compile Elm programs online with no download or install.},
   author = {Evan Czaplicki},
   journal = {Master thesis, Harvard University},
   title = {Elm: Concurrent FRP for Functional GUIs},
   year = {2012},
}
@inproceedings{Czaplicki2013,
   abstract = {Graphical user interfaces (GUIs) mediate many of our interactions with computers. Functional Reactive Programming (FRP) is a promising approach to GUI design, providing high-level, declarative, compositional abstractions to describe user interactionsa},
   author = {Evan Czaplicki and Stephen Chong},
   doi = {10.1145/2491956.2462161},
   isbn = {9781450320146},
   issn = {15232867},
   journal = {Proceedings of the 34th ACM SIGPLAN conference on Programming language design and implementation - PLDI '13},
   title = {Asynchronous functional reactive programming for GUIs},
   year = {2013},
}
@article{Liu2011,
   abstract = {Abstract Arrows are a popular form of abstract computation. Being more general than monads, they are more broadly applicable, and in particular are a good abstraction for signal processing and dataflow computations. Most notably, arrows form the basis for a ... \n},
   author = {Hai Liu and Eric Cheng and Paul Hudak},
   doi = {10.1017/S0956796811000153},
   isbn = {9781605583327},
   issn = {14697653},
   journal = {Journal of Functional Programming},
   title = {Causal commutative arrows},
   year = {2011},
}
@article{Lindley2010,
   abstract = {Abstract We introduce the arrow calculus , a metalanguage for manipulating Hughes's arrows with close relations both to Moggi's metalanguage for monads and to Paterson's arrow notation. Arrows are classically defined by extending lambda calculus with three ... \n},
   author = {Sam Lindley and Philip Wadler and Jeremy Yallop},
   doi = {10.1017/S095679680999027X},
   issn = {09567968},
   journal = {Journal of Functional Programming},
   title = {The arrow calculus},
   year = {2010},
}
@inproceedings{Curien2016,
   abstract = {We consider the Curry-Howard-Lambek correspondence for effect- ful computation and resource management, specifically proposing polarised calculi together with presheaf-enriched adjunction mod- els as the starting point for a comprehensive semantic theory relat- ing logical systems, typed calculi, and categorical models in this context. Our thesis is that the combination of effects and resources should be considered orthogonally. Model theoretically, this leads to an understanding of our categorical models from two complementary perspectives: (i) as a linearisation of CBPV (Call-by-Push-Value) adjunction models, and (ii) as an extension of linear/non-linear ad- junction models with an adjoint resolution of computational effects. When the linear structure is cartesian and the resource structure is trivial we recover Levy’s notion of CBPV adjunction model, while when the effect structure is trivial we have Benton’s linear/non- linear adjunction models. Further instances of our model theory in- clude the dialogue categories with a resource modality of Melliès and Tabareau, and the [E]EC ([Enriched] Effect Calculus) models of Egger, Møgelberg and Simpson. Our development substantiates the approach by providing a lifting theorem of linear models into cartesian ones. To each of our categorical models we systematically associate a typed term calculus, each of which corresponds to a variant of the sequent calculi LJ (Intuitionistic Logic) or ILL (Intuitionistic Linear Logic). The adjoint resolution of effects corresponds to po- larisation whereby, syntactically, types locally determine a strict or lazy evaluation order and, semantically, the associativity of cuts is relaxed. In particular, our results show that polarisation provides a computational interpretation of CBPV in direct style. Further, we characterise depolarised models: those where the cut is associative, and where the evaluation order is unimportant.We explain possible advantages of this style of calculi for the operational semantics of effects},
   author = {Pierre-Louis Curien and Marcelo Fiore and Guillaume Munch-Maccagnoni},
   doi = {10.1145/2837614.2837652},
   isbn = {9781450335492},
   issn = {15232867},
   journal = {Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages - POPL 2016},
   title = {A theory of effects and resources: adjunction models and polarised calculi},
   year = {2016},
}
@inproceedings{Letan2018,
   author = {Thomas Letan and Yann Régis-Gianas and Pierre Chifflier and Guillaume Hiet},
   city = {Oxford, United Kingdom},
   journal = {FM 2018 - 22nd  International Symposium on Formal Methods},
   month = {7},
   pages = {1-17},
   title = {Modular Verification of Programs with Effects and Effect Handlers in Coq},
   url = {https://hal.inria.fr/hal-01799712},
   year = {2018},
}
@article{Egger2014,
   abstract = {This article introduces the enriched effect calculus, which extends established type theories for computational effects with primitives from linear logic. The new calculus provides a formalism for expressing linear aspects of computational effects; e.g. the linear usage of imperative features such as state and/or continuations. The enriched effect calculus is implemented as an extension of a basic effect calculus without linear primitives, which is closely related to Moggi's computational metalanguage, Filinski's effect PCF and Levy's call-by-push-value. We present syntactic results showing: the fidelity of the behaviour of the linear connectives of the enriched effect calculus; the conservativity of the enriched effect calculus over its non-linear core (the effect calculus); and the non-conservativity of intuitionistic linear logic when considered as an extension of the enriched effect calculus. The second half of the article investigates models for the enriched effect calculus, based on enriched category theory. We give several examples of such models, relating them to models of standard effect calculi (such as those based on monads), and to models of intuitionistic linear logic. We also prove soundness and completeness.},
   author = {Jeff Egger and Rasmus Ejlers Møgelberg and Alex Simpson},
   doi = {10.1093/logcom/exs025},
   issn = {1465363X},
   journal = {Journal of Logic and Computation},
   keywords = {Computational effects,Linear logic},
   title = {The enriched effect calculus: Syntax and semantics},
   year = {2014},
}
@article{Egger2014,
   abstract = {This article introduces the enriched effect calculus, which extends established type theories for computational effects with primitives from linear logic. The new calculus provides a formalism for expressing linear aspects of computational effects; e.g. the linear usage of imperative features such as state and/or continuations. The enriched effect calculus is implemented as an extension of a basic effect calculus without linear primitives, which is closely related to Moggi's computational metalanguage, Filinski's effect PCF and Levy's call-by-push-value. We present syntactic results showing: the fidelity of the behaviour of the linear connectives of the enriched effect calculus; the conservativity of the enriched effect calculus over its non-linear core (the effect calculus); and the non-conservativity of intuitionistic linear logic when considered as an extension of the enriched effect calculus. The second half of the article investigates models for the enriched effect calculus, based on enriched category theory. We give several examples of such models, relating them to models of standard effect calculi (such as those based on monads), and to models of intuitionistic linear logic. We also prove soundness and completeness.},
   author = {Jeff Egger and Rasmus Ejlers Møgelberg and Alex Simpson},
   doi = {10.1093/logcom/exs025},
   issn = {1465363X},
   journal = {Journal of Logic and Computation},
   keywords = {Computational effects,Linear logic},
   title = {The enriched effect calculus: Syntax and semantics},
   year = {2014},
}
@article{Pilkiewicz2011,
   abstract = {We extend a static type-and-capability system with new mechanisms for expressing the promise that a certain abstract value evolves monotonically with time; for enforcing this promise; and for taking advantage of this promise to establish non-trivial properties of programs. These mechanisms are independent of the treatment of mutable state, but combine with it to offer a flexible account of "monotonic state". We apply these mechanisms to solve two reasoning challenges that involve mutable state. First, we show how an implementation of thunks in terms of references can be assigned types that reflect time complexity properties, in the style of Danielsson (2008). Second, we show how an implementation of hash-consing can be assigned a specification that conceals the existence of an internal state yet guarantees that two pieces of input data receive the same hash code if and only if they are equal.},
   author = {Alexandre Pilkiewicz and François Pottier},
   doi = {10.1145/1929553.1929565},
   isbn = {9781450304849},
   journal = {Proceedings of the 7th ACM SIGPLAN workshop on Types in language design and implementation - TLDI '11},
   keywords = {amortized complexity,capabilities,hash-consing,hidden state,mono-,specification,thunks,tonic state,type-based complexity-checking,types},
   title = {The essence of monotonic state},
   year = {2011},
}
@inproceedings{Plotkin2008,
   abstract = {We present a logic for algebraic effects, based on the algebraic representation of computational effects by operations and equations. We begin with the a-calculus, a minimal calculus which separates values, effects, and computations and thereby canonises the order of evaluation. This is extended to obtain the logic, which is a classical first-order multi-sorted logic with higher-order value and computation types, as in Levy's call-by-push-value, a principle of induction over computations, a free algebra principle, and predicate fixed points. This logic embraces Moggi's computational lambda-calculus, and also, via definable modalities, Hennessy-Milner logic, and evaluation logic, though Hoare logic presents difficulties.},
   author = {Gordon Plotkin and Matija Pretnar},
   doi = {10.1109/LICS.2008.45},
   isbn = {9780769531830}\,
   issn = {10436871},
   journal = {Proceedings - Symposium on Logic in Computer Science},
   title = {A logic for algebraic effects},
   year = {2008},
}
@inproceedings{Plotkin2001,
   abstract = {Given a category C with finite products and a strong monad T on C, we investigate axioms under which an ObC-indexed family of operations of the form αx:(Tx)n → Tx provides a definitive semantics for algebraic operations added to the computational λ-calculus. We recall a definition for which we have elsewhere given adequacy results for both big and small step operational semantics, and we show that it is equivalent to a range of other possible natural definitions of algebraic operation. We outline examples and non-examples and we show that our definition is equivalent to one for call-by-name languages with effects, too. © 2001 Published by Elsevier Science B.V.},
   author = {Gordon Plotkin and John Power},
   doi = {10.1016/S1571-0661(04)80970-8},
   issn = {15710661},
   journal = {Electronic Notes in Theoretical Computer Science},
   title = {Semantics for algebraic operations},
   year = {2001},
}
@article{Plotkin2013,
   abstract = {Algebraic effects are computational effects that can be represented by an equa- tional theory whose operations produce the effects at hand. The free model of this theory induces the expected computational monad for the corresponding effect. Algebraic effects include exceptions, state, nondeterminism, interactive input/output, and time, and their combinations. Exception handling, however, has so far received no algebraic treatment. We present such a treatment, in which each handler yields a model of the theory for ex- ceptions, and each handling construct yields the homomorphism induced by the universal property of the free model. We further generalise exception handlers to arbitrary algebraic effects. The resulting programming construct includes many previously unrelated exam- ples from both theory and practice, including relabelling and restriction in Milner’s CCS, timeout, rollback, and stream redirection.},
   author = {Gordon D. Plotkin and Matija Pretnar},
   doi = {10.2168/LMCS-9(4:23)2013},
   isbn = {978-3-642-19717-8},
   issn = {18605974},
   journal = {Logical Methods in Computer Science},
   keywords = {Algebraic effects,Exception handlers,Generalised handlers},
   title = {Handling algebraic effects},
   year = {2013},
}
@article{Plotkin2003,
   abstract = {Given a complete and cocomplete symmetric monoidal closed category V and a symmetric monoidal V-category C with cotensors and a strong V-monad T on C, we investigate axioms under which an Ob C-indexed family of operations of the form α x :(Tx) v →(Tx) w provides semantics for algebraic operations on the computational λ-calculus. We recall a definition for which we have elsewhere given adequacy results, and we show that an enrichment of it is equivalent to a range of other possible natural definitions of algebraic operation. In particular, we define the notion of generic effect and show that to give a generic effect is equivalent to giving an algebraic operation. We further show how the usual monadic semantics of the computational λ-calculus extends uniformly to incorporate generic effects. We outline examples and non-examples and we show that our definition also enriches one for call-by-name languages with effects.},
   author = {Gordon Plotkin and John Power},
   doi = {10.1023/A:1023064908962},
   isbn = {9783642157202},
   issn = {09272852},
   journal = {Applied Categorical Structures},
   keywords = {Algebraic operation,Computational effect,Lawvere theory,Monad},
   pmid = {1284},
   title = {Algebraic operations and generic effects},
   year = {2003},
}
@inproceedings{Plotkin2009,
   abstract = {We present an algebraic treatment of exception handlers and, more generally, introduce handlers for other computational effects representable by an algebraic theory. These include nondeterminism, interactive input/output, concurrency, state, time, and their combinations; in all cases the computation monad is the free-model monad of the theory. Each such handler corresponds to a model of the theory for the effects at hand. The handling construct, which applies a handler to a computation, is based on the one introduced by Benton and Kennedy, and is interpreted using the homomorphism induced by the universal property of the free model. This general construct can be used to describe previously unrelated concepts from both theory and practice.},
   author = {Gordon Plotkin and Matija Pretnar},
   doi = {10.1007/978-3-642-00590-9_7},
   isbn = {9783642005893},
   issn = {03029743},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Handlers of algebraic effects},
   year = {2009},
}
@article{,
   abstract = {We consider CSP from the point of view of the algebraic theory of effects, which classifies operations as effect constructors or effect deconstructors; it also provides a link with functional programming, being a refinement of Moggi's seminal monadic point of view. There is a natural algebraic theory of the constructors whose free algebra functor is Moggi's monad; we illustrate this by characterising free and initial algebras in terms of two versions of the stable failures model of CSP, one more general than the other. Deconstructors are dealt with as homomorphisms to (possibly non-free) algebras. One can view CSP's action and choice operators as constructors and the rest, such as concealment and concurrency, as deconstructors. Carrying this programme out results in taking deterministic external choice as constructor rather than general external choice. However, binary deconstructors, such as the CSP concurrency operator, provide unresolved difficulties. We conclude by presenting a combination of CSP with Moggi's computational lambda-calculus, in which the operators, including concurrency, are polymorphic. While the paper mainly concerns CSP, it ought to be possible to carry over similar ideas to other process calculi.},
   author = {Rob Van Glabbeek and Gordon Plotkin},
   doi = {10.1007/978-1-84882-912-1_15},
   journal = {unknown},
   title = {On CSP and the Algebraic Theory of Effects},
   year = {2010},
}
@inproceedings{Lucassen1988,
   abstract = {We present a new approach to programming languages for parallel computers that uses an effect system to discover expression scheduling constraints. This effect system is part of a 'kinded' type system with three base kinds: types , which describe the value that an expression may return; effects , which describe the side-effects that an expression may have; and regions , which describe the area of the store in which side-effects may occur. Types, effects and regions are collectively called descriptions . Expressions can be abstracted over any kind of description variable -- this permits type, effect and region polymorphism. Unobservable side-effects can be masked by the effect system; an effect soundness property guarantees that the effects computed statically by the effect system are a conservative approximation of the actual side-effects that a given expression may have. The effect system we describe performs certain kinds of side-effect analysis that were not previously feasible. Experimental data from the programming language FX indicate that an effect system can be used effectively to compile programs for parallel computers.},
   author = {J. M. Lucassen and D. K. Gifford},
   doi = {10.1145/73560.73564},
   isbn = {0897912527},
   issn = {07308566},
   journal = {Proceedings of the 15th ACM SIGPLAN-SIGACT symposium on Principles of programming languages  - POPL '88},
   title = {Polymorphic effect systems},
   year = {1988},
}
@article{Mcbride2008,
   abstract = {In this paper, we introduce Applicative functors—an abstract characterisation of an ap- plicative style of effectful programming, weaker than Monads and hence more widespread. Indeed, it is the ubiquity of this programming pattern that drew us to the abstraction. We retrace our steps in this paper, introducing the applicative pattern by diverse exam- ples, then abstracting it to define the Applicative type class and introducing a bracket notation which interprets the normal application syntax in the idiom of an Applicative functor. Further, we develop the properties of applicative functors and the generic opera- tions they support.We close by identifying the categorical structure of applicative functors and examining their relationship both with Monads and with Arrows.},
   author = {Conor Mcbride and Ross Paterson},
   doi = {10.1017/S0956796807006326},
   isbn = {0956-7968},
   issn = {09567968},
   journal = {Journal of Functional Programming},
   title = {Applicative programming with effects},
   year = {2008},
}
@inproceedings{Marlow2016,
   author = {Simon Marlow and Simon Peyton Jones and Edward Kmett and Andrey Mokhov},
   city = {New York, New York, USA},
   doi = {10.1145/2976002.2976007},
   isbn = {9781450344340},
   journal = {Proceedings of the 9th International Symposium on Haskell - Haskell 2016},
   keywords = {Applicative Functors,Monads,concurrency,parallelism},
   pages = {92-104},
   publisher = {ACM Press},
   title = {Desugaring Haskell's do-notation into applicative operations},
   url = {http://dl.acm.org/citation.cfm?doid=2976002.2976007},
   year = {2016},
}
@article{,
   author = {Sam Lindley and Sam Lindley},
   title = {Algebraic Effects and Effect Handlers for Idioms and Arrows},
   url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.465.8321},
}
@article{Lindley2011,
   author = {Sam Lindley and Philip Wadler and Jeremy Yallop},
   doi = {10.1016/j.entcs.2011.02.018},
   issn = {15710661},
   issue = {5},
   journal = {Electronic Notes in Theoretical Computer Science},
   keywords = {applicative functors,arrows,idioms,monads},
   month = {3},
   pages = {97-117},
   publisher = {Elsevier Science Publishers B. V.},
   title = {Idioms are Oblivious, Arrows are Meticulous, Monads are Promiscuous},
   volume = {229},
   url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066111000557},
   year = {2011},
}
@book_section{Hudak2003,
   author = {Paul Hudak and Antony Courtney and Henrik Nilsson and John Peterson},
   doi = {10.1007/978-3-540-44833-4_6},
   pages = {159-187},
   publisher = {Springer, Berlin, Heidelberg},
   title = {Arrows, Robots, and Functional Reactive Programming},
   url = {http://link.springer.com/10.1007/978-3-540-44833-4_6},
   year = {2003},
}
@book{,
   abstract = {Second edition. "The visual arts are rapidly changing as media moves into the web, mobile devices, and architecture. When designers and artists learn the basics of writing software, they develop a new form of literacy that enables them to create new media for the present, and to imagine future media that are beyond the capacities of current software tools. This book introduces this new literacy by teaching computer programming within the context of the visual arts. It offers a comprehensive reference and text for Processing (www.processing.org), an open-source programming language that can be used by students, artists, designers, architects, researchers, and anyone who wants to program images, animation, and interactivity. Written by Processing's cofounders, the book offers a definitive reference for students and professionals. Tutorial chapters make up the bulk of the book; advanced professional projects from such domains as animation, performance, and installation are discussed in interviews wit their creators. This second edition has been thoroughly updated. It is the first book to offer in-depth coverage of Processing 2.0 and 3.0, and all examples have been updated for the new syntax. Every chapter has been revised, and new chapters introduce new ways to work with data and geometry. New "synthesis" chapters offer discussion and worked examples of such topics as sketching with code, modularity, and algorithms. New interviews have been added that cover a wider range of projects. "Extension" chapters are now offered online so they can be updated to keep pace with technological developments in such fields as computer vision and electronics." 1. Processing ... -- Software -- Literacy -- Open -- Education -- Network -- Context -- 2. Using Processing -- Download, Install -- Environment -- Export -- Example walk-through -- Coding is writing -- Comments -- Functions -- Expressions, Statements -- Case sensitivity -- Whitespace -- Console -- Reference -- 3. Draw -- Coordinates -- Basic shapes -- Curves -- Drawing order -- Gray values -- Attributes -- Modes -- 4. Color -- Color by number -- Blend -- RGB, HSB -- Hexadecimal -- 5. Variables -- Data types -- Variables -- Variable names -- Processing variables -- Arithmetic -- Mind the data types -- Data conversion -- Order of operations -- Shortcuts -- 6. Flow -- Looping -- Controlling the flow -- Relational expressions -- Conditionals -- Logical operators -- Variable scope -- Formatting code blocks -- 7. Interactivity -- Mouse data -- Mouse buttons -- Keyboard data -- Coded keys -- Events -- Mouse events -- Key events -- Event flow -- Cursor icon. 8. Repeat -- Iterate -- While Loop -- For Loop -- Loop and draw() -- Nested loops -- 9. Synthesis 1 -- Sketching software -- Programming techniques -- Examples -- 10. Interviews: Image -- Manfred Mohr, Une Esthetique Programmee -- LettError, RandomFont Beowolf -- Jared Tarbell, Fractal Invaders, Substrate -- Benjamin Maus, Perpetual Storytelling Apparatus -- 11. Text -- Characters -- Words, Sentences -- Strings are objects -- 12. Typography -- Draw text -- Load media -- Vector fonts -- Pixel fonts -- Text attributes -- Typing -- Typography and interaction -- 13. Image -- Display -- Tint, Transparency -- Filter -- Mask -- 14. Transform -- Translate -- Controlling transformations -- Rotate -- Scale -- Combining transformations -- Transformation and interaction -- New coordinate systems -- 15. Vertices -- Vertex -- Points, Lines -- Geometry -- Curves -- Contours -- 16.3D Drawing -- 3D form -- Camera -- Lights, Materials -- Texture maps -- 17. Shapes -- Display SVG. Display OBJ -- Transform -- Create -- Modify -- 18. Synthesis 2 -- Iteration -- Debugging -- Examples -- 19. Interviews: Interaction -- Lynn Hershman Leeson, Lorna -- Robert Winter, Ludwig van Beethoven: Symphony No. 9 -- Josh On, They Rule -- Steph Thirion, Eliss -- 20. Calculate -- Exponents, Roots -- Normalize, Map -- Simple curves -- Constraining numbers -- Distance -- Easing -- Angles, Waves -- Circles, Spirals -- Direction -- 21. Random -- Unexpected values -- Distributions -- Random seed -- Noise -- 22. Motion -- Controlling motion -- Motion along curves -- Mechanical motion -- Organic motion -- Kinetic typography -- 23. Time -- Seconds, Minutes, Hours -- Milliseconds -- Date -- 24. Functions -- Abstraction -- Why functions? -- Create functions -- Overload functions -- Calculate and return values -- Parameterize -- Recursion -- 25. Objects -- Object-oriented programming -- Classes and objects -- Multiple files -- Multiple constructors. Composite objects -- Inheritance -- 26. Synthesis 3 -- Modularity, reusability -- Algorithm -- Examples -- 27. Interviews: Motion, Performance -- Larry Cuba, Calculated Movements -- Bob Sabiston, Waking Life -- Golan Levin and Zachary Lieberman, Messa di Voce -- SUE. C, Mini Movies -- 28. Arrays -- Define an array -- Read array elements -- Record data -- Array functions -- Arrays of objects -- Two-dimensional arrays -- 29. Animation -- Arrays of images -- Animation format, resolution -- Save sequential images -- 30. Dynamic Drawing -- Simple tools -- Draw with media -- Speed -- Orientation -- Drawings in motion -- Active tools -- 31. Simulate -- Motion -- Particle systems -- Springs -- Cellular automata -- Autonomous agents -- 32. Data -- Format data -- Export files -- Data structure -- Strings -- Table -- XML -- JSON -- 33. Interface -- Rollover, Button -- Drag and drop -- Checkboxes -- Radio buttons -- Scrollbar -- 34. Image Processing -- Read pixels. Write pixels -- Copy pixels -- Color components -- Pixel array -- Pixel components -- 35. Render Techniques -- Renderers -- Another drawing surface -- OpenGL surfaces -- Combine surfaces -- 36. Synthesis 4 -- Collage engine -- Waves -- 3D Letter -- Noise landscape -- Network -- 37. Interviews: Environment -- Mark Hansen, Listening Post -- Jurg Lehni, Hektor and Scriptographer -- Jennifer Steinkamp, Madame Curie -- Ash Nehru, Origin -- 38. Continuing ... -- Extend Processing -- Processing and Java -- Other programming languages.},
   author = {Casey Reas and Ben Fry},
   isbn = {026202828X},
   pages = {642},
   title = {Processing : a programming handbook for visual designers and artists},
}
@article{Moggi1991,
   abstract = {The λ-calculus is considered a useful mathematical tool in the study of programming languages, since programs can be identified with λ-terms. However, if one goes further and uses βη-conversion to prove equivalence of programs, then a gross simplification is introduced (programs are identified with total functions from values to values) that may jeopardise the applicability of theoretical results. In this paper we introduce calculi, based on a categorical semantics for computations, that provide a correct basis for proving equivalence of programs for a wide range of notions of computation.},
   author = {Eugenio Moggi},
   doi = {10.1016/0890-5401(91)90052-4},
   issn = {0890-5401},
   issue = {1},
   journal = {Information and Computation},
   month = {7},
   pages = {55-92},
   publisher = {Academic Press},
   title = {Notions of computation and monads},
   volume = {93},
   url = {https://www.sciencedirect.com/science/article/pii/0890540191900524},
   year = {1991},
}
@inproceedings{Dolan2016,
   abstract = {Non-deterministic computations are conventionally modelled by lists of their
outcomes. This approach provides a concise declarative description of certain
problems, as well as a way of generically solving such problems. However, the
traditional approach falls short when the non-deterministic problem is
allowed to be recursive: the recursive problem may have infinitely many
outcomes, giving rise to an infinite list. Yet there are usually only finitely
many distinct relevant results. This paper shows that this set of interesting
results corresponds to a least fixed point. We provide an implementation based
on algebraic effect handlers to compute such least fixed points in a finite
amount of time, thereby allowing non-determinism and recursion to meaningfully
co-occur in a single program.
},
   author = {Stephen Dolan and Alan Mycroft and Tim Freeman and Frank Pfenning and Ryan R. Newton and Ömer S. Ağacan and Peter Fogg and Sam Tobin-Hochstadt and Ryan R. Newton and Ömer S. Ağacan and Peter Fogg and Sam Tobin-Hochstadt and Lindsey Kuper and Ryan R. Newton and Ezgi Çiçek and Zoe Paraskevopoulou and Deepak Garg and Pedro B. Vasconcelos and Kevin Hammond and Alvaro J Rebon Portillo and Kevin Hammond and Hans-wolfgang Loidl and Pedro B. Vasconcelos and Hugo R Simões and Kevin Hammond and Mário Florido and Pedro B. Vasconcelos and Hans-wolfgang Loidl and Kevin Hammond and Ohad Kammar and Sam Lindley and Nicolas Oury and Ohad Kammar and Sam Lindley and Nicolas Oury and Andrej Bauer and Matija Pretnar and Daan Leijen and  Daan and Simon Marlow and Ryan R. Newton and Simon Peyton Jones and Simon Marlow and Ryan R. Newton and Simon Peyton Jones and Lindsey Kuper and Aaron Todd and Sam Tobin-Hochstadt and Ryan R. Newton and Lindsey Kuper and Aaron Todd and Sam Tobin-Hochstadt and Ryan R. Newton and Aaron Turon and Neelakantan R. Krishnaswami and Ryan R. Newton and Lindsey Kuper and Aaron Turon and Neelakantan R. Krishnaswami and Ryan R. Newton and Nicolas Wu and Tom Schrijvers and Alexander Vandenbroucke and Tom Schrijvers and Frank Piessens and Nicolas Wu and Tom Schrijvers and Ralf Hinze and Matija Pretnar and Andrej Bauer and Matija Pretnar},
   city = {New York, New York, USA},
   doi = {10.1016/j.entcs.2015.12.003},
   isbn = {9781450346603},
   issn = {0362-1340},
   issue = {1},
   journal = {Implementation of Functional Languages, 14th International Workshop, IFL 2002},
   keywords = {Algebra,Algebraic effects,Complexity analysis,Koka,Polymorphism,Subtyping,Type Inference,algebraic effects,asynchronous programming,continuations,deterministic parallelism,effect handlers,effect types,effect typing,haskell,incremental computation,lattices,modularity,monads,parallel,quasi-determinism,type and effect systems},
   month = {7},
   pages = {232-248},
   publisher = {ACM Press},
   title = {Fusion for Free: Efficient Algebraic Effect Handlers},
   volume = {51},
   url = {https://doi.org/10.2168/LMCS-10(4:9)2014 https://doi.org/10.1016/j.jlamp.2014.02.001 https://doi.org/10.1016/j.entcs.2015.12.003 /Research/papers/haskell2014.pdf /Research/papers/ifl2015_post.pdf /Research/papers/mpc2015.pdf http://dl.acm.org/citation.cfm},
   year = {2016},
}
@article{Bauer2014,
   author = {Andrej Bauer and Matija Pretnar},
   doi = {10.2168/LMCS-10(4:9)2014},
   issue = {4},
   journal = {Logical Methods in Computer Science},
   title = {An Effect System for Algebraic Effects and Handlers},
   volume = {10},
   url = {https://doi.org/10.2168/LMCS-10(4:9)2014},
   year = {2014},
}
@inproceedings{Wu2015,
   abstract = {Algebraic effect handlers are a recently popular approach for
modelling side-effects that separates the syntax and semantics of
effectful operations. The shape of syntax is captured by functors, and
free monads over these functors denote syntax trees. The semantics is
captured by algebras, and effect handlers pass these over the syntax
trees to interpret them into a semantic domain.
This approach is inherently modular: different functors can be
composed to make trees with richer structure. Such trees are
interpreted by applying several handlers in sequence, each removing
the syntactic constructs it recognizes. Unfortunately, the
construction and traversal of intermediate trees is painfully
inefficient and has hindered the adoption of the handler approach.
This paper explains how a sequence of handlers can be fused into one, so that
multiple tree traversals can be reduced to a single one and no intermediate
trees need to be allocated. At the heart of this optimization is keeping the
notion of a free monad abstract, thus enabling a change of representation that
opens up the possibility of fusion. We demonstrate how the ensuing code can be
inlined at compile time to produce efficient handlers.
},
   author = {Nicolas Wu and Tom Schrijvers},
   journal = {MPC 2015},
   title = {Fusion for Free: Efficient Algebraic Effect Handlers},
   url = {/Research/papers/mpc2015.pdf},
   year = {2015},
}
@inproceedings{Vandenbroucke2016,
   abstract = {Non-deterministic computations are conventionally modelled by lists of their
outcomes. This approach provides a concise declarative description of certain
problems, as well as a way of generically solving such problems. However, the
traditional approach falls short when the non-deterministic problem is
allowed to be recursive: the recursive problem may have infinitely many
outcomes, giving rise to an infinite list. Yet there are usually only finitely
many distinct relevant results. This paper shows that this set of interesting
results corresponds to a least fixed point. We provide an implementation based
on algebraic effect handlers to compute such least fixed points in a finite
amount of time, thereby allowing non-determinism and recursion to meaningfully
co-occur in a single program.
},
   author = {Alexander Vandenbroucke and Tom Schrijvers and Frank Piessens},
   city = {New York, NY, USA},
   doi = {10.1145/2897336.2897342},
   journal = {Proceedings of the 27th Symposium on the Implementation and Application of Functional Programming Languages},
   pages = {5:1--5:12},
   publisher = {ACM},
   title = {Fixing Non-determinism},
   url = {/Research/papers/ifl2015_post.pdf},
   year = {2016},
}
@article{Pretnar2015,
   author = {Matija Pretnar},
   doi = {10.1016/j.entcs.2015.12.003},
   journal = {Electr. Notes Theor. Comput. Sci.},
   pages = {19-35},
   title = {An Introduction to Algebraic Effects and Handlers. Invited tutorial paper},
   volume = {319},
   url = {https://doi.org/10.1016/j.entcs.2015.12.003},
   year = {2015},
}
@article{Bauer2015,
   author = {Andrej Bauer and Matija Pretnar},
   doi = {10.1016/j.jlamp.2014.02.001},
   issue = {1},
   journal = {J. Log. Algebr. Meth. Program.},
   pages = {108-123},
   title = {Programming with algebraic effects and handlers},
   volume = {84},
   url = {https://doi.org/10.1016/j.jlamp.2014.02.001},
   year = {2015},
}
@inproceedings{Wu2014,
   abstract = {Algebraic effect handlers are a powerful means for describing
effectful computations. They provide a lightweight and orthogonal
technique to define and compose the syntax and semantics of different
effects. The semantics is captured by handlers, which are functions
that transform syntax trees.
Unfortunately, the approach does not support syntax for scoping
constructs, which arise in a number of scenarios. While handlers can
be used to provide a limited form of scope, we demonstrate that this
approach constrains the possible interactions of effects and rules out
some desired semantics.
This paper presents two different ways to capture scoped constructs in
syntax, and shows how to achieve different semantics by reordering
handlers. The first approach expresses scopes using the existing
algebraic handlers framework, but has some limitations. The problem is
fully solved in the second approach where we introduce higher-order
syntax.
},
   author = {Nicolas Wu and Tom Schrijvers and Ralf Hinze},
   journal = {Haskell 2014},
   title = {Effect Handlers in Scope},
   url = {/Research/papers/haskell2014.pdf},
   year = {2014},
}
@article{Vazou2014,
   abstract = {SMT-based checking of refinement types for call-by-value languages is a well-studied subject. Unfortunately, the classical translation of refinement types to verification conditions is unsound under lazy evaluation. When checking an expression, such systems implicitly assume that all the free variables in the expression are bound to values. This property is trivially guaranteed by eager, but does not hold under lazy, evaluation. Thus, to be sound and precise, a refinement type system for Haskell and the corresponding verification conditions must take into account which subset of binders actually reduces to values. We present a stratified type system that labels binders as potentially diverging or not, and that (circularly) uses refinement types to verify the labeling. We have implemented our system in LIQUIDHASKELL and present an experimental evaluation of our approach on more than 10,000 lines of widely used Haskell libraries. We show that LIQUIDHASKELL is able to prove 96% of all recursive functions terminating, while requiring a modest 1.7 lines of termination-annotations per 100 lines of code.},
   author = {Niki Vazou and Eric L. Seidel and Ranjit Jhala and Dimitrios Vytiniotis and Simon Peyton-Jones},
   doi = {10.1145/2692915.2628161},
   isbn = {9781450325677},
   issn = {03621340},
   issue = {9},
   journal = {ACM SIGPLAN Notices},
   title = {Refinement types for Haskell},
   volume = {49},
   year = {2014},
}
@inproceedings{Swamy2016,
   abstract = {We present F , a new language that works both as a proof assis-tant as well as a general-purpose, verification-oriented, effectful programming language. In support of these complementary roles, F is a dependently typed, higher-order, call-by-value language with primitive effects including state, exceptions, divergence and IO. Although primitive, programmers choose the granularity at which to specify effects by equipping each effect with a monadic, predicate transformer semantics. F uses this to efficiently compute weakest preconditions and discharges the resulting proof obligations using a combination of SMT solving and manual proofs. Isolated from the effects, the core of F is a language of pure functions used to write specifications and proof terms—its consistency is maintained by a semantic termination check based on a well-founded order. We evaluate our design on more than 55,000 lines of F we have authored in the last year, focusing on three main case studies. Showcasing its use as a general-purpose programming language, F is programmed (but not verified) in F , and bootstraps in both OCaml and F#. Our experience confirms F 's pay-as-you-go cost model: writing idiomatic ML-like code with no finer specifications imposes no user burden. As a verification-oriented language, our most significant evaluation of F is in verifying several key modules in an implementation of the TLS-1.2 protocol standard. For the modules we considered, we are able to prove more properties, with fewer annotations using F than in a prior verified implementation of TLS-1.2. Finally, as a proof assistant, we discuss our use of F in mechanizing the metatheory of a range of lambda calculi, starting from the simply typed lambda calculus to F ω and even µF , a sizeable fragment of F itself—these proofs make essential use of F 's flexible combination of SMT automation and constructive proofs, enabling a tactic-free style of programming and proving at a relatively large scale.},
   author = {Nikhil Swamy and Markulf Kohlweiss and Jean-karim Zinzindohoue and Santiago Zanella-Béguelin and Cătălin Hriţcu and Chantal Keller and Aseem Rastogi and Antoine Delignat-Lavaud and Simon Forest and Karthikeyan Bhargavan and Cédric Fournet and Pierre-yves Strub},
   doi = {10.1145/2837614.2837655},
   isbn = {9781450335492},
   issn = {15232867},
   journal = {Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages - POPL 2016},
   title = {Dependent types and multi-monadic effects in F*},
   year = {2016},
}
@inproceedings{Kiselyov2013,
   abstract = {We design and implement a library that solves the long-standing problem of combining effects without imposing restrictions on their interactions (such as static ordering). Effects arise from interactions between a client and an effect handler (interpreter); interactions may vary throughout the program and dynamically adapt to exe- cution conditions. Existing code that relies on monad transform- ers may be used with our library with minor changes, gaining effi- ciency over long monad stacks. In addition, our library has greater expressiveness, allowing for practical idioms that are inefficient, cumbersome, or outright impossible with monad transformers. Our alternative to a monad transformer stack is a single monad, for the coroutine-like communication of a client with its handler. Its type reflects possible requests, i.e., possible effects of a com- putation. To support arbitrary effects and their combinations, re- quests are values of an extensible union type, which allows adding and, notably, subtracting summands. Extending and, upon han- dling, shrinking of the union of possible requests is reflected in its type, yielding a type-and-effect system for Haskell. The library is lightweight, generalizing the extensible exception handling to other effects and accurately tracking them in types.},
   author = {Oleg Kiselyov and Amr Sabry and Cameron Swords},
   doi = {10.1145/2503778.2503791},
   isbn = {9781450323833},
   issn = {15232867},
   journal = {Haskell Symposium},
   title = {Extensible effects: an alternative to monad transformers},
   year = {2013},
}
@inproceedings{McBride2015,
   abstract = {In this paper, I show that general recursive definitions can be represented in the free monad which supports the 'effect' of making a recur-sive call, without saying how these calls should be executed. Diverse seman-tics can be given within a total framework by suitable monad morphisms. The Bove-Capretta construction of the domain of a general recursive func-tion can be presented datatype-generically as an instance of this technique. The paper is literate Agda, but its key ideas are more broadly transferable.},
   author = {Conor McBride},
   doi = {10.1007/978-3-319-19797-5_13},
   isbn = {9783319197968},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Turing-completeness totally free},
   volume = {9129},
   year = {2015},
}
@article{Pretnar2014,
   abstract = {We present a complete polymorphic effect inference algorithm for an ML-style language with handlers of not only exceptions, but of any other algebraic effect such as input & output, mutable references and many others. Our main aim is to offer the programmer a useful insight into the effectful behaviour of programs. Handlers help here by cutting down possible effects and the resulting lengthy output that often plagues precise effect systems. Additionally, we present a set of meth-ods that further simplify the displayed types, some even by deliberately hiding inferred information from the programmer. Though Haskell [10] fans may not think it is better to write impure programs in ML [18], they do agree it is easier. You can insert a harmless printout without rewriting the rest of the program, and you can combine multiple effects without a monad transformer. This flexibility comes at a cost, though — ML types offer no insight into what effects may happen. The suggested solution is to use an effect system [16, 29, 4, 31, 33, 3, 27], which enriches existing types with information about effects. An effect system can play two roles: it can be descriptive and inform about potential effects, and it can be prescriptive and limit the allowed ones. In this paper, we focus on the former. It turns out that striking a balance between expressiveness and simplicity of a descriptive effect system is hard. One of the bigger problems is that effects tend to pile up, and if the effect system takes them all into account, we are often left with a lengthy output listing every single effect there is. In this paper, we present a complete inference algorithm for an expressive and simple descriptive polymorphic effect system of Eff [2] (freely available at http://eff-lang.org), an ML-style language with handlers of not only exceptions, but of any other algebraic effect [22] such as input & output, non-determinism, mutable references and many oth-ers [23, 2]. Handlers prove to be extremely versatile and can express stream redirection, transactional memory, backtracking, cooperative multi-threading, delimited continuations, and, like monads, give programmers a way to define their own. And as handlers eliminate effects, they make the effect system non-monotone, which helps with the above issue of a snowballing output. 2012 ACM CCS: [Theory of computation]: Semantics and reasoning—Program reasoning—Program analysis.},
   author = {Matija Pretnar},
   doi = {10.2168/LMCS-10(3:21)2014},
   isbn = {9783939897255},
   issn = {18605974},
   issue = {3},
   journal = {Logical Methods in Computer Science},
   title = {Inferring algebraic effects},
   volume = {10},
   year = {2014},
}
@inproceedings{Kiselyov2015,
   abstract = {We present a rational reconstruction of extensible effects, the recently proposed alternative to monad transformers, as the confluence of efforts to make effectful computations compose. Free monads and then extensible effects emerge from the straightforward term representation of an effectful computation, as more and more boilerplate is abstracted away. The generalization process further leads to freer monads, constructed without the Functor constraint. The continuation exposed in freer monads can then be represented as an efficient type-aligned data structure. The end result is the algorithmically efficient extensible effects library, which is not only more comprehensible but also faster than earlier implementations. As an illustration of the new library, we show three surprisingly simple applications: non-determinism with committed choice (LogicT), catching IO exceptions in the presence of other effects, and the semi-automatic management of file handles and other resources through monadic regions. We extensively use and promote the new sort of `laziness', which underlies the left Kan extension: instead of performing an operation, keep its operands and pretend it is done.},
   author = {Oleg Kiselyov and Hiromi Ishii},
   doi = {10.1145/2804302.2804319},
   isbn = {9781450338080},
   issn = {03621340},
   journal = {Proceedings of the 8th ACM SIGPLAN Symposium on Haskell - Haskell 2015},
   title = {Freer monads, more extensible effects},
   year = {2015},
}
@article{Plotkin2013,
   abstract = {Algebraic effects are computational effects that can be represented by an equa- tional theory whose operations produce the effects at hand. The free model of this theory induces the expected computational monad for the corresponding effect. Algebraic effects include exceptions, state, nondeterminism, interactive input/output, and time, and their combinations. Exception handling, however, has so far received no algebraic treatment. We present such a treatment, in which each handler yields a model of the theory for ex- ceptions, and each handling construct yields the homomorphism induced by the universal property of the free model. We further generalise exception handlers to arbitrary algebraic effects. The resulting programming construct includes many previously unrelated exam- ples from both theory and practice, including relabelling and restriction in Milner’s CCS, timeout, rollback, and stream redirection.},
   author = {Gordon D. Plotkin and Matija Pretnar},
   doi = {10.2168/LMCS-9(4:23)2013},
   isbn = {978-3-642-19717-8},
   issn = {18605974},
   issue = {4},
   journal = {Logical Methods in Computer Science},
   title = {Handling algebraic effects},
   volume = {9},
   year = {2013},
}
@inproceedings{Pretnar2015,
   abstract = {This paper is a tutorial on algebraic effects and handlers. In it, we explain what algebraic effects are, give ample examples to explain how handlers work, define an operational semantics and a type & effect system, show how one can reason about effects, and give pointers for further reading.},
   author = {Matija Pretnar},
   doi = {10.1016/j.entcs.2015.12.003},
   issn = {15710661},
   journal = {Electronic Notes in Theoretical Computer Science},
   title = {An Introduction to Algebraic Effects and Handlers. Invited tutorial paper},
   volume = {319},
   year = {2015},
}
@article{Brady2013,
   abstract = {One often cited benefit of pure functional programming is that pure code is easier to test and reason about, both formally and informally. However, real programs have side-effects including state management, exceptions and interactions with the outside world. Haskell solves this problem using monads to capture details of pos- sibly side-effecting computations—it provides monads for capturing State, I/O, exceptions, non-determinism, libraries for practical purposes such as CGI and parsing, and many others, as well as monad transformers for combining multiple effects. Unfortunately, useful as monads are, they do not compose very well. Monad transformers can quickly become unwieldy when there are lots of effects to manage, leading to a temptation in larger programs to combine everything into one coarse-grained state and exception monad. In this paper I describe an alternative approach based on handling algebraic effects, implemented in the IDRIS programming language. I show how to describe side effecting computations, how to write programs which compose multiple fine-grained effects, and how, using dependent types, we can use this approach to reason about states in effectful programs.},
   author = {Edwin Brady},
   doi = {10.1145/2544174.2500581},
   isbn = {9781450323260},
   issn = {03621340},
   issue = {9},
   journal = {ACM SIGPLAN Notices},
   title = {Programming and reasoning with algebraic effects and dependent types},
   volume = {48},
   year = {2013},
}
@article{Cockx2014,
   abstract = {Dependent pattern matching is an intuitive way to write programs and proofs in dependently typed languages. It is reminiscent of both pattern matching in functional languages and case analysis in on-paper mathematics. However, in general it is incompatible with new type theories such as homotopy type theory (HoTT). As a consequence, proofs in such theories are typically harder to write and to understand. The source of this incompatibility is the reliance of dependent pattern matching on the so-called K axiom – also known as the uniqueness of identity proofs – which is inadmissible in HoTT. The Agda language supports an experimental criterion to detect definitions by pattern matching that make use of the K axiom, but so far it lacked a formal correctness proof. In this paper, we propose a new criterion for dependent pat- tern matching without K, and prove it correct by a translation to eliminators in the style of Goguen et al. (2006). Our criterion both allows more good definitions than existing proposals, and solves a previously undetected problem in the criterion offered by Agda. It has been implemented in Agda and is the first to be supported by a formal proof. Thus it brings the benefits of dependent pattern matching to contexts where we cannot assume K, such as HoTT. It also points the way to new forms of dependent pattern matching, for example on higher inductive types.},
   author = {Jesper Cockx and Dominique Devriese and Frank Piessens},
   doi = {10.1145/2628136.2628139},
   isbn = {9781450328739},
   issn = {03621340},
   issue = {5},
   journal = {Proceedings of the 19th ACM SIGPLAN international conference on Functional programming - ICFP '14},
   title = {Pattern matching without K},
   year = {2014},
}
@article{Kuper2014,
   author = {Lindsey Kuper and Aaron Turon and Neelakantan R. Krishnaswami and Ryan R. Newton and Lindsey Kuper and Aaron Turon and Neelakantan R. Krishnaswami and Ryan R. Newton},
   doi = {10.1145/2578855.2535842},
   isbn = {978-1-4503-2544-8},
   issn = {0362-1340},
   issue = {1},
   journal = {ACM SIGPLAN Notices},
   keywords = {deterministic parallelism,lattices,quasi-determinism},
   pages = {257-270},
   publisher = {ACM},
   title = {Freeze after writing: quasi-deterministic parallel programming with LVars},
   volume = {49},
   url = {http://dl.acm.org/citation.cfm?id=2535842&CFID=979563870&CFTOKEN=39164737},
   year = {2014},
}
@article{Kuper2014,
   author = {Lindsey Kuper and Aaron Todd and Sam Tobin-Hochstadt and Ryan R. Newton and Lindsey Kuper and Aaron Todd and Sam Tobin-Hochstadt and Ryan R. Newton},
   doi = {10.1145/2666356.2594312},
   isbn = {978-1-4503-2784-8},
   issn = {03621340},
   issue = {6},
   journal = {ACM SIGPLAN Notices},
   keywords = {deterministic parallelism},
   month = {6},
   pages = {2-14},
   publisher = {ACM},
   title = {Taming the parallel effect zoo},
   volume = {49},
   url = {http://dl.acm.org/citation.cfm?doid=2666356.2594312},
   year = {2014},
}
@article{Marlow2012,
   author = {Simon Marlow and Ryan Newton and Simon Peyton Jones and Simon Marlow and Ryan Newton and Simon Peyton Jones},
   doi = {10.1145/2096148.2034685},
   isbn = {978-1-4503-0860-1},
   issn = {03621340},
   issue = {12},
   journal = {ACM SIGPLAN Notices},
   keywords = {haskell,parallel},
   month = {1},
   pages = {71},
   publisher = {ACM},
   title = {A monad for deterministic parallelism},
   volume = {46},
   url = {http://dl.acm.org/citation.cfm?doid=2096148.2034685},
   year = {2012},
}
@inproceedings{Leijen2017,
   author = {Daan Leijen and  Daan},
   city = {New York, New York, USA},
   doi = {10.1145/3122975.3122977},
   isbn = {9781450351836},
   journal = {Proceedings of the 2nd ACM SIGPLAN International Workshop on Type-Driven Development  - TyDe 2017},
   keywords = {Algebraic effects,Koka,asynchronous programming,effect types},
   pages = {16-29},
   publisher = {ACM Press},
   title = {Structured asynchrony with algebraic effects},
   url = {http://dl.acm.org/citation.cfm?doid=3122975.3122977},
   year = {2017},
}
@article{Bauer2012,
   abstract = {Eff is a programming language based on the algebraic approach to computational effects, in which effects are viewed as algebraic operations and effect handlers as homomorphisms from free algebras. Eff supports first-class effects and handlers through which we may easily define new computational effects, seamlessly combine existing ones, and handle them in novel ways. We give a denotational semantics of eff and discuss a prototype implementation based on it. Through examples we demonstrate how the standard effects are treated in eff, and how eff supports programming techniques that use various forms of delimited continuations, such as backtracking, breadth-first search, selection functionals, cooperative multi-threading, and others.},
   author = {Andrej Bauer and Matija Pretnar},
   doi = {10.1016/j.jlamp.2014.02.001},
   month = {3},
   title = {Programming with Algebraic Effects and Handlers},
   url = {http://arxiv.org/abs/1203.1539 http://dx.doi.org/10.1016/j.jlamp.2014.02.001},
   year = {2012},
}
@inproceedings{Kammar2013,
   author = {Ohad Kammar and Sam Lindley and Nicolas Oury and Ohad Kammar and Sam Lindley and Nicolas Oury},
   city = {New York, New York, USA},
   doi = {10.1145/2500365.2500590},
   isbn = {9781450323260},
   issn = {0362-1340},
   issue = {9},
   journal = {Proceedings of the 18th ACM SIGPLAN international conference on Functional programming - ICFP '13},
   keywords = {algebraic effects,continuations,effect handlers,effect typing,haskell,modularity,monads},
   pages = {145},
   publisher = {ACM Press},
   title = {Handlers in action},
   volume = {48},
   url = {http://dl.acm.org/citation.cfm?doid=2500365.2500590},
   year = {2013},
}
@inproceedings{Loidl1996,
   author = {Hans-Wolfgang Loidl and Kevin Hammond},
   city = {Ullapool, Scotland},
   journal = {Proceedings of the Glasgow Workshop on Functional Programming},
   month = {7},
   title = {A Sized Time System for a Parallel Functional Language},
   year = {1996},
}
@inproceedings{,
   author = {Hugo R Simões and Kevin Hammond and Mário Florido and Pedro Vasconcelos},
   city = {Berlin, Heidelberg},
   isbn = {3-540-74463-0, 978-3-540-74463-4},
   journal = {Proceedings of the 2006 International Conference on Types for Proofs and Programs},
   pages = {221-236},
   publisher = {Springer-Verlag},
   title = {Using Intersection Types for Cost-analysis of Higher-order Polymorphic Functional Programs},
   url = {http://dl.acm.org/citation.cfm?id=1789277.1789292},
   year = {2007},
}
@inproceedings{Portillo2002,
   author = {Alvaro J Rebon Portillo and Kevin Hammond and Hans-wolfgang Loidl and Pedro Vasconcelos},
   journal = {Implementation of Functional Languages, 14th International Workshop, IFL 2002},
   pages = {232-248},
   publisher = {Springer},
   title = {Cost Analysis using Automatic Size and Time Inference},
   year = {2002},
}
@book_section{Vasconcelos2004,
   author = {Pedro B. Vasconcelos and Kevin Hammond},
   doi = {10.1007/978-3-540-27861-0_6},
   isbn = {3-540-23727-5, 978-3-540-23727-3},
   journal = {Proceedings of the 15th international conference on Implementation of Functional Languages},
   pages = {86-101},
   publisher = {Springer-Verlag},
   title = {Inferring Cost Equations for Recursive, Polymorphic and Higher-Order Functional Programs},
   url = {http://link.springer.com/10.1007/978-3-540-27861-0_6},
   year = {2004},
}
@inproceedings{,
   author = {Ezgi Çiçek and Zoe Paraskevopoulou and Deepak Garg},
   city = {New York, New York, USA},
   doi = {10.1145/2951913.2951950},
   isbn = {9781450342193},
   issn = {0362-1340},
   issue = {9},
   journal = {Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming - ICFP 2016},
   keywords = {Complexity analysis,incremental computation,type and effect systems},
   pages = {132-145},
   publisher = {ACM Press},
   title = {A type theory for incremental computational complexity with control flow changes},
   volume = {51},
   url = {http://dl.acm.org/citation.cfm?doid=2951913.2951950},
   year = {2016},
}
@inproceedings{Kuper2013,
   author = {Lindsey Kuper and Ryan R. Newton},
   city = {New York, New York, USA},
   doi = {10.1145/2502323.2502326},
   isbn = {9781450323819},
   journal = {Proceedings of the 2nd ACM SIGPLAN workshop on Functional high-performance computing - FHPC '13},
   keywords = {deterministic parallelism,lattices},
   pages = {71},
   publisher = {ACM Press},
   title = {LVars: lattice-based data structures for deterministic parallelism},
   url = {http://dl.acm.org/citation.cfm?doid=2502323.2502326},
   year = {2013},
}
@inproceedings{Newton2016,
   author = {Ryan R. Newton and Ömer S. Ağacan and Peter Fogg and Sam Tobin-Hochstadt and Ryan R. Newton and Ömer S. Ağacan and Peter Fogg and Sam Tobin-Hochstadt},
   city = {New York, New York, USA},
   doi = {10.1145/2851141.2851142},
   isbn = {9781450340922},
   issn = {0362-1340},
   issue = {8},
   journal = {Proceedings of the 21st ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming - PPoPP '16},
   pages = {1-12},
   publisher = {ACM Press},
   title = {Parallel type-checking with haskell using saturating LVars and stream generators},
   volume = {51},
   url = {http://dl.acm.org/citation.cfm?doid=2851141.2851142},
   year = {2016},
}
@inproceedings{Freeman1991,
   author = {Tim Freeman and Frank Pfenning},
   city = {New York, New York, USA},
   doi = {10.1145/113445.113468},
   isbn = {0897914287},
   issn = {0362-1340},
   issue = {6},
   journal = {Proceedings of the ACM SIGPLAN 1991 conference on Programming language design and implementation - PLDI '91},
   pages = {268-277},
   publisher = {ACM Press},
   title = {Refinement types for ML},
   volume = {26},
   url = {http://portal.acm.org/citation.cfm?doid=113445.113468},
   year = {1991},
}
@inproceedings{Dolan2017,
   author = {Stephen Dolan and Alan Mycroft},
   city = {New York, New York, USA},
   doi = {10.1145/3009837.3009882},
   isbn = {9781450346603},
   journal = {Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages  - POPL 2017},
   keywords = {Algebra,Polymorphism,Subtyping,Type Inference},
   pages = {60-72},
   publisher = {ACM Press},
   title = {Polymorphism, subtyping, and type inference in MLsub},
   url = {http://dl.acm.org/citation.cfm?doid=3009837.3009882},
   year = {2017},
}
@inproceedings{Claret2013,
   abstract = {Proof-by-reflection is a well-established technique that employs decision procedures to reduce the size of proof-terms. Currently, decision procedures can be written either in Type Theory - in a purely functional way that also ensures termination - or in an effectful programming language, where they are used as oracles for the certified checker. The first option offers strong correctness guarantees, while the second one permits more efficient implementations. We propose a novel technique for proof-by-reflection that marries, in Type Theory, an effectful language with (partial) proofs of correctness. The key to our approach is to use simulable monads, where a monad is simulable if, for all terminating reduction sequences in its equivalent effectful computational model, there exists a witness from which the same reduction may be simulated a posteriori by the monad. We encode several examples using simulable monads and demonstrate the advantages of the technique over previous approaches. © 2013 Springer-Verlag.},
   author = {Guillaume Claret and Lourdes Del Carmen González Huesca and Yann Régis-Gianas and Beta Ziliani},
   doi = {10.1007/978-3-642-39634-2_8},
   isbn = {9783642396335},
   issn = {03029743},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   pages = {67-83},
   publisher = {Springer, Berlin, Heidelberg},
   title = {Lightweight proof by reflection using a posteriori simulation of effectful computation},
   volume = {7998 LNCS},
   url = {https://link.springer.com/chapter/10.1007/978-3-642-39634-2_8},
   year = {2013},
}
@article{Convent2020,
   author = {Lukas Convent and Sam Lindley and Conor McBride and Craig McLaughlin},
   doi = {10.1017/S0956796820000039},
   journal = {J. Funct. Program.},
   pages = {e9},
   title = {Doo bee doo bee doo},
   volume = {30},
   url = {https://doi.org/10.1017/S0956796820000039},
   year = {2020},
}
